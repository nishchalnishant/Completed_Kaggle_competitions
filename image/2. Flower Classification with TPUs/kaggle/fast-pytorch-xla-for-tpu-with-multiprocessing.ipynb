{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 2**: disable unfreezing for speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup for pytorch/xla on TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libomp5\r\n",
      "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\r\n",
      "Need to get 228 kB of archives.\r\n",
      "After this operation, 750 kB of additional disk space will be used.\r\n",
      "Get:1 http://deb.debian.org/debian stretch/main amd64 libomp5 amd64 3.9.1-1 [228 kB]\r\n",
      "Fetched 228 kB in 0s (5208 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "(Reading database ... 59973 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libomp5_3.9.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (3.9.1-1) ...\r\n",
      "Setting up libomp5:amd64 (3.9.1-1) ...\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libopenblas-base\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libopenblas-base libopenblas-dev\r\n",
      "0 upgraded, 2 newly installed, 0 to remove and 32 not upgraded.\r\n",
      "Need to get 7602 kB of archives.\r\n",
      "After this operation, 91.5 MB of additional disk space will be used.\r\n",
      "Get:1 http://deb.debian.org/debian stretch/main amd64 libopenblas-base amd64 0.2.19-3 [3793 kB]\r\n",
      "Get:2 http://deb.debian.org/debian stretch/main amd64 libopenblas-dev amd64 0.2.19-3 [3809 kB]\r\n",
      "Fetched 7602 kB in 0s (35.9 MB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libopenblas-base.\r\n",
      "(Reading database ... 59978 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libopenblas-base_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-base (0.2.19-3) ...\r\n",
      "Selecting previously unselected package libopenblas-dev.\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev (0.2.19-3) ...\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\r\n",
      "Setting up libopenblas-base (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so.3 to provide /usr/lib/libblas.so.3 (libblas.so.3) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so.3 to provide /usr/lib/liblapack.so.3 (liblapack.so.3) in auto mode\r\n",
      "Setting up libopenblas-dev (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so to provide /usr/lib/libblas.so (libblas.so) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so to provide /usr/lib/liblapack.so (liblapack.so) in auto mode\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\r\n",
      "Found existing installation: torch 1.4.0\r\n",
      "Uninstalling torch-1.4.0:\r\n",
      "  Successfully uninstalled torch-1.4.0\r\n",
      "Found existing installation: torchvision 0.5.0\r\n",
      "Uninstalling torchvision-0.5.0:\r\n",
      "  Successfully uninstalled torchvision-0.5.0\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/77.8 MiB.                                     \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/112.7 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.5 MiB.                                      \r\n",
      "Processing ./torch-nightly-cp36-cp36m-linux_x86_64.whl\r\n",
      "\u001b[31mERROR: fastai 1.0.60 requires torchvision, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: catalyst 20.2.1 requires torchvision>=0.2.1, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.3 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-1.5.0a0+e0b90b8\r\n",
      "Processing ./torch_xla-nightly-cp36-cp36m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-0.8+f1455a7\r\n",
      "Processing ./torchvision-nightly-cp36-cp36m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (1.18.1)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (5.4.1)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (1.5.0a0+e0b90b8)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (1.14.0)\r\n",
      "Installing collected packages: torchvision\r\n",
      "Successfully installed torchvision-0.6.0a0+b2e9565\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "os.environ[\"XRT_TPU_CONFIG\"] = \"tpu_worker;0;10.0.0.2:8470\"\n",
    "\n",
    "_VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\n",
    "VERSION = \"torch_xla==nightly\"\n",
    "CONFIG = {\n",
    "    'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n",
    "        (datetime.today() - timedelta(1)).strftime('%Y%m%d')))}[VERSION]\n",
    "\n",
    "DIST_BUCKET = 'gs://tpu-pytorch/wheels'\n",
    "TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
    "TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
    "TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
    "\n",
    "!export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\n",
    "!apt-get install libomp5 -y\n",
    "!apt-get install libopenblas-dev -y\n",
    "\n",
    "!pip uninstall -y torch torchvision\n",
    "!gsutil cp \"$DIST_BUCKET/$TORCH_WHEEL\" .\n",
    "!gsutil cp \"$DIST_BUCKET/$TORCH_XLA_WHEEL\" .\n",
    "!gsutil cp \"$DIST_BUCKET/$TORCHVISION_WHEEL\" .\n",
    "!pip install \"$TORCH_WHEEL\"\n",
    "!pip install \"$TORCH_XLA_WHEEL\"\n",
    "!pip install \"$TORCHVISION_WHEEL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import requests, threading\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.data_parallel as dp\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not uncomment see https://github.com/pytorch/xla/issues/1587\n",
    "\n",
    "# xm.get_xla_supported_devices()\n",
    "# xm.xrt_world_size() # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '/kaggle/input/104-flowers-garden-of-eden/jpeg-512x512'\n",
    "TRAIN_DIR  = DATASET_DIR + '/train'\n",
    "VAL_DIR  = DATASET_DIR + '/val'\n",
    "TEST_DIR  = DATASET_DIR + '/test'\n",
    "BATCH_SIZE = 16 # per core \n",
    "NUM_EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(0.5),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      normalize])\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images:  16465\n",
      "Num test images:  3712\n"
     ]
    }
   ],
   "source": [
    "train = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "valid = datasets.ImageFolder(VAL_DIR, transform=train_transform)\n",
    "train = torch.utils.data.ConcatDataset([train, valid])\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train))\n",
    "print('Num test images: ', len(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.base_model = torchvision.models.densenet201(pretrained=True)\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(1920, 1024, bias = True),\n",
    "                    torch.nn.BatchNorm1d(1024),\n",
    "                    torch.nn.ReLU(inplace=True),\n",
    "                    torch.nn.Dropout(0.3),\n",
    "                    torch.nn.Linear(1024, 512, bias = True),\n",
    "                    torch.nn.BatchNorm1d(512),\n",
    "                    torch.nn.ReLU(inplace=True),\n",
    "                    torch.nn.Dropout(0.3),\n",
    "                    torch.nn.Linear(512, 104))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.base_model(inputs)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/checkpoints/densenet201-c1103571.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e392bc982f4ad0aa696bd2ec951de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81131730.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MyModel(\n",
      "  (base_model): DenseNet(\n",
      "    (features): Sequential(\n",
      "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu0): ReLU(inplace=True)\n",
      "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (denseblock1): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition1): _Transition(\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock2): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition2): _Transition(\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock3): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer25): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer26): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer27): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer28): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer29): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer30): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer31): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer32): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer33): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer34): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer35): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer36): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer37): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer38): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer39): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer40): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer41): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer42): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer43): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer44): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer45): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer46): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer47): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer48): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition3): _Transition(\n",
      "        (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock4): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer25): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer26): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer27): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer28): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer29): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer30): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer31): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer32): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (classifier): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1920, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=512, out_features=104, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "print(model)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    train = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "    valid = datasets.ImageFolder(VAL_DIR, transform=train_transform)\n",
    "    train = torch.utils.data.ConcatDataset([train, valid])\n",
    "    \n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=0,\n",
    "        drop_last=True) # print(len(train_loader))\n",
    "    \n",
    "    \n",
    "    xm.master_print(f\"Train for {len(train_loader)} steps per epoch\")\n",
    "    \n",
    "    # Scale learning rate to num cores\n",
    "    learning_rate = 0.0001 * xm.xrt_world_size()\n",
    "\n",
    "    # Get loss function, optimizer, and model\n",
    "    device = xm.xla_device()\n",
    "\n",
    "    model = MyModel()\n",
    "    \n",
    "    for param in model.base_model.parameters(): # freeze some layers\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model = model.to(device)\n",
    "    loss_fn =  nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "    scheduler = OneCycleLR(optimizer, \n",
    "                           learning_rate, \n",
    "                           div_factor=10.0, \n",
    "                           final_div_factor=50.0, \n",
    "                           epochs=NUM_EPOCH,\n",
    "                           steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_loop_fn(loader):\n",
    "        tracker = xm.RateTracker()\n",
    "        model.train()\n",
    "        total_samples, correct = 0, 0\n",
    "        for x, (data, target) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer)\n",
    "            tracker.add(data.shape[0])\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total_samples += data.size()[0]\n",
    "            scheduler.step()\n",
    "            if x % 40 == 0:\n",
    "                print('[xla:{}]({})\\tLoss={:.3f}\\tRate={:.2f}\\tGlobalRate={:.2f}'.format(\n",
    "                    xm.get_ordinal(), x, loss.item(), tracker.rate(),\n",
    "                    tracker.global_rate()), flush=True)\n",
    "        accuracy = 100.0 * correct / total_samples\n",
    "        print('[xla:{}] Accuracy={:.2f}%'.format(xm.get_ordinal(), accuracy), flush=True)\n",
    "        return accuracy\n",
    "\n",
    "    # Train loops\n",
    "    accuracy = []\n",
    "    for epoch in range(1, NUM_EPOCH + 1):\n",
    "        start = time.time()\n",
    "        para_loader = pl.ParallelLoader(train_loader, [device])\n",
    "        accuracy.append(train_loop_fn(para_loader.per_device_loader(device)))\n",
    "        xm.master_print(\"Finished training epoch {} train-acc {:.2f} in {:.2f} sec\"\\\n",
    "                        .format(epoch, accuracy[-1], time.time() - start))\n",
    "        xm.save(model.state_dict(), \"./model.pt\")\n",
    "\n",
    "#         if epoch == 15: #unfreeze\n",
    "#             for param in model.base_model.parameters():\n",
    "#                 param.requires_grad = True\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 128 steps per epoch\n",
      "[xla:1](0)\tLoss=4.989\tRate=0.89\tGlobalRate=0.89\n",
      "[xla:3](0)\tLoss=4.780\tRate=0.81\tGlobalRate=0.81\n",
      "[xla:4](0)\tLoss=4.716\tRate=0.81\tGlobalRate=0.81\n",
      "[xla:2](0)\tLoss=4.723\tRate=0.69\tGlobalRate=0.69\n",
      "[xla:7](0)\tLoss=4.702\tRate=0.83\tGlobalRate=0.83\n",
      "[xla:0](0)\tLoss=4.785\tRate=0.57\tGlobalRate=0.57\n",
      "[xla:5](0)\tLoss=4.939\tRate=0.70\tGlobalRate=0.70\n",
      "[xla:6](0)\tLoss=4.991\tRate=0.73\tGlobalRate=0.73\n",
      "[xla:6](40)\tLoss=4.108\tRate=8.98\tGlobalRate=9.93\n",
      "[xla:2](40)\tLoss=3.599\tRate=8.96\tGlobalRate=9.73\n",
      "[xla:1](40)\tLoss=3.885\tRate=9.04\tGlobalRate=10.55\n",
      "[xla:0](40)\tLoss=3.802\tRate=8.91\tGlobalRate=9.08\n",
      "[xla:5](40)\tLoss=4.445\tRate=8.97\tGlobalRate=9.77\n",
      "[xla:3](40)\tLoss=4.046\tRate=9.01\tGlobalRate=10.27\n",
      "[xla:7](40)\tLoss=4.111\tRate=9.02\tGlobalRate=10.33\n",
      "[xla:4](40)\tLoss=4.295\tRate=9.01\tGlobalRate=10.28\n",
      "[xla:2](80)\tLoss=3.008\tRate=17.59\tGlobalRate=13.66\n",
      "[xla:7](80)\tLoss=3.415\tRate=17.61\tGlobalRate=14.25\n",
      "[xla:6](80)\tLoss=3.197\tRate=17.60\tGlobalRate=13.86\n",
      "[xla:3](80)\tLoss=3.940\tRate=17.61\tGlobalRate=14.20\n",
      "[xla:1](80)\tLoss=3.327\tRate=17.62\tGlobalRate=14.47\n",
      "[xla:5](80)\tLoss=2.703\tRate=17.59\tGlobalRate=13.70\n",
      "[xla:0](80)\tLoss=3.016\tRate=17.57\tGlobalRate=13.00\n",
      "[xla:4](80)\tLoss=3.871\tRate=17.61\tGlobalRate=14.20\n",
      "[xla:7](120)\tLoss=3.458\tRate=21.58\tGlobalRate=16.50\n",
      "[xla:5](120)\tLoss=3.633\tRate=21.57\tGlobalRate=16.00\n",
      "[xla:3](120)\tLoss=2.451\tRate=21.57\tGlobalRate=16.45\n",
      "[xla:4](120)\tLoss=2.573\tRate=21.58\tGlobalRate=16.45\n",
      "[xla:1](120)\tLoss=2.963\tRate=21.58\tGlobalRate=16.69\n",
      "[xla:2](120)\tLoss=2.925\tRate=21.57\tGlobalRate=15.96\n",
      "[xla:6](120)\tLoss=2.663\tRate=21.57\tGlobalRate=16.14\n",
      "[xla:0](120)\tLoss=2.882\tRate=21.56\tGlobalRate=15.35\n",
      "[xla:2] Accuracy=23.83%\n",
      "[xla:3] Accuracy=24.27%\n",
      "[xla:0] Accuracy=24.17%\n",
      "[xla:1] Accuracy=24.12%\n",
      "[xla:4] Accuracy=23.34%\n",
      "[xla:5] Accuracy=22.66%\n",
      "Finished training epoch 1 train-acc 24.17 in 128.63 sec\n",
      "[xla:7] Accuracy=22.95%\n",
      "[xla:6] Accuracy=23.14%\n",
      "[xla:7](0)\tLoss=2.414\tRate=5.76\tGlobalRate=5.76\n",
      "[xla:0](0)\tLoss=2.922\tRate=5.77\tGlobalRate=5.77\n",
      "[xla:6](0)\tLoss=2.563\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:1](0)\tLoss=2.955\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:4](0)\tLoss=2.739\tRate=5.77\tGlobalRate=5.77\n",
      "[xla:3](0)\tLoss=2.165\tRate=5.83\tGlobalRate=5.83\n",
      "[xla:5](0)\tLoss=2.761\tRate=5.75\tGlobalRate=5.75\n",
      "[xla:2](0)\tLoss=2.325\tRate=5.76\tGlobalRate=5.76\n",
      "[xla:3](40)\tLoss=3.028\tRate=16.53\tGlobalRate=22.02\n",
      "[xla:0](40)\tLoss=2.728\tRate=16.51\tGlobalRate=22.00\n",
      "[xla:6](40)\tLoss=2.971\tRate=16.51\tGlobalRate=22.00\n",
      "[xla:4](40)\tLoss=3.325\tRate=16.51\tGlobalRate=22.00\n",
      "[xla:7](40)\tLoss=3.123\tRate=16.50\tGlobalRate=21.99\n",
      "[xla:2](40)\tLoss=2.441\tRate=16.50\tGlobalRate=21.99\n",
      "[xla:5](40)\tLoss=3.490\tRate=16.49\tGlobalRate=21.99\n",
      "[xla:1](40)\tLoss=2.592\tRate=16.51\tGlobalRate=22.00\n",
      "[xla:6](80)\tLoss=2.163\tRate=17.94\tGlobalRate=20.35\n",
      "[xla:1](80)\tLoss=2.347\tRate=17.94\tGlobalRate=20.35\n",
      "[xla:7](80)\tLoss=2.023\tRate=17.94\tGlobalRate=20.35\n",
      "[xla:4](80)\tLoss=3.082\tRate=17.94\tGlobalRate=20.35\n",
      "[xla:2](80)\tLoss=1.798\tRate=17.94\tGlobalRate=20.35\n",
      "[xla:3](80)\tLoss=2.853\tRate=17.95\tGlobalRate=20.36\n",
      "[xla:5](80)\tLoss=2.171\tRate=17.94\tGlobalRate=20.35\n",
      "[xla:0](80)\tLoss=2.048\tRate=17.94\tGlobalRate=20.35\n",
      "[xla:5](120)\tLoss=2.252\tRate=21.94\tGlobalRate=21.58\n",
      "[xla:1](120)\tLoss=2.023\tRate=21.94\tGlobalRate=21.59\n",
      "[xla:4](120)\tLoss=1.703\tRate=21.94\tGlobalRate=21.58\n",
      "[xla:2](120)\tLoss=2.222\tRate=21.94\tGlobalRate=21.58\n",
      "[xla:3](120)\tLoss=1.383\tRate=21.94\tGlobalRate=21.59\n",
      "[xla:6](120)\tLoss=1.686\tRate=21.94\tGlobalRate=21.59\n",
      "[xla:0](120)\tLoss=2.221\tRate=21.94\tGlobalRate=21.58\n",
      "[xla:7](120)\tLoss=2.730\tRate=21.94\tGlobalRate=21.58\n",
      "[xla:5] Accuracy=44.58%\n",
      "[xla:1] Accuracy=46.00%\n",
      "[xla:7] Accuracy=44.78%\n",
      "[xla:6] Accuracy=45.51%\n",
      "[xla:3] Accuracy=45.31%\n",
      "[xla:0] Accuracy=48.19%\n",
      "[xla:2] Accuracy=45.90%\n",
      "Finished training epoch 2 train-acc 48.19 in 92.46 sec\n",
      "[xla:4] Accuracy=46.68%\n",
      "[xla:2](0)\tLoss=1.348\tRate=6.10\tGlobalRate=6.10\n",
      "[xla:5](0)\tLoss=1.965\tRate=6.05\tGlobalRate=6.05\n",
      "[xla:1](0)\tLoss=2.241\tRate=6.02\tGlobalRate=6.02\n",
      "[xla:7](0)\tLoss=1.871\tRate=6.05\tGlobalRate=6.05\n",
      "[xla:6](0)\tLoss=1.966\tRate=6.06\tGlobalRate=6.06\n",
      "[xla:0](0)\tLoss=2.161\tRate=6.07\tGlobalRate=6.07\n",
      "[xla:3](0)\tLoss=1.798\tRate=6.09\tGlobalRate=6.09\n",
      "[xla:4](0)\tLoss=2.093\tRate=6.01\tGlobalRate=6.01\n",
      "[xla:2](40)\tLoss=1.825\tRate=17.35\tGlobalRate=23.12\n",
      "[xla:0](40)\tLoss=1.859\tRate=17.34\tGlobalRate=23.11\n",
      "[xla:3](40)\tLoss=2.373\tRate=17.35\tGlobalRate=23.12\n",
      "[xla:1](40)\tLoss=2.128\tRate=17.32\tGlobalRate=23.09\n",
      "[xla:6](40)\tLoss=2.580\tRate=17.34\tGlobalRate=23.10\n",
      "[xla:7](40)\tLoss=2.253\tRate=17.33\tGlobalRate=23.10\n",
      "[xla:5](40)\tLoss=2.722\tRate=17.33\tGlobalRate=23.10\n",
      "[xla:4](40)\tLoss=2.187\tRate=17.32\tGlobalRate=23.09\n",
      "[xla:4](80)\tLoss=2.246\tRate=18.03\tGlobalRate=20.57\n",
      "[xla:7](80)\tLoss=1.302\tRate=18.04\tGlobalRate=20.58\n",
      "[xla:0](80)\tLoss=1.371\tRate=18.04\tGlobalRate=20.58\n",
      "[xla:3](80)\tLoss=2.093\tRate=18.04\tGlobalRate=20.58\n",
      "[xla:5](80)\tLoss=1.693\tRate=18.04\tGlobalRate=20.58\n",
      "[xla:1](80)\tLoss=1.771\tRate=18.03\tGlobalRate=20.57\n",
      "[xla:2](80)\tLoss=1.094\tRate=18.04\tGlobalRate=20.58\n",
      "[xla:6](80)\tLoss=1.144\tRate=18.04\tGlobalRate=20.58\n",
      "[xla:3](120)\tLoss=0.705\tRate=19.41\tGlobalRate=20.50\n",
      "[xla:0](120)\tLoss=1.308\tRate=19.41\tGlobalRate=20.50\n",
      "[xla:4](120)\tLoss=0.973\tRate=19.41\tGlobalRate=20.49\n",
      "[xla:2](120)\tLoss=1.732\tRate=19.42\tGlobalRate=20.50\n",
      "[xla:1](120)\tLoss=1.382\tRate=19.41\tGlobalRate=20.49\n",
      "[xla:5](120)\tLoss=1.643\tRate=19.41\tGlobalRate=20.50\n",
      "[xla:6](120)\tLoss=0.947\tRate=19.41\tGlobalRate=20.50\n",
      "[xla:7](120)\tLoss=1.808\tRate=19.41\tGlobalRate=20.50\n",
      "[xla:7] Accuracy=62.21%\n",
      "[xla:4] Accuracy=64.16%\n",
      "[xla:5] Accuracy=62.11%\n",
      "[xla:2] Accuracy=63.92%\n",
      "[xla:6] Accuracy=62.94%\n",
      "[xla:0] Accuracy=65.14%\n",
      "[xla:1] Accuracy=63.18%\n",
      "[xla:3] Accuracy=62.94%\n",
      "Finished training epoch 3 train-acc 65.14 in 97.13 sec\n",
      "[xla:7](0)\tLoss=1.025\tRate=5.97\tGlobalRate=5.97\n",
      "[xla:4](0)\tLoss=1.531\tRate=5.98\tGlobalRate=5.98\n",
      "[xla:3](0)\tLoss=0.876\tRate=5.92\tGlobalRate=5.92\n",
      "[xla:5](0)\tLoss=1.339\tRate=5.86\tGlobalRate=5.86\n",
      "[xla:0](0)\tLoss=1.646\tRate=5.88\tGlobalRate=5.88\n",
      "[xla:6](0)\tLoss=1.246\tRate=5.90\tGlobalRate=5.90\n",
      "[xla:1](0)\tLoss=1.717\tRate=5.85\tGlobalRate=5.85\n",
      "[xla:2](0)\tLoss=0.940\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:1](40)\tLoss=1.652\tRate=17.00\tGlobalRate=22.68\n",
      "[xla:3](40)\tLoss=1.223\tRate=17.01\tGlobalRate=22.68\n",
      "[xla:0](40)\tLoss=1.591\tRate=17.01\tGlobalRate=22.69\n",
      "[xla:4](40)\tLoss=1.548\tRate=17.04\tGlobalRate=22.70\n",
      "[xla:5](40)\tLoss=1.994\tRate=17.00\tGlobalRate=22.68\n",
      "[xla:6](40)\tLoss=1.340\tRate=17.02\tGlobalRate=22.69\n",
      "[xla:2](40)\tLoss=1.142\tRate=16.99\tGlobalRate=22.67\n",
      "[xla:7](40)\tLoss=1.014\tRate=17.03\tGlobalRate=22.70\n",
      "[xla:4](80)\tLoss=1.145\tRate=21.72\tGlobalRate=23.71\n",
      "[xla:7](80)\tLoss=0.659\tRate=21.71\tGlobalRate=23.71\n",
      "[xla:6](80)\tLoss=0.885\tRate=21.71\tGlobalRate=23.70\n",
      "[xla:0](80)\tLoss=1.229\tRate=21.71\tGlobalRate=23.70\n",
      "[xla:2](80)\tLoss=0.829\tRate=21.70\tGlobalRate=23.69\n",
      "[xla:1](80)\tLoss=1.204\tRate=21.70\tGlobalRate=23.69\n",
      "[xla:3](80)\tLoss=1.697\tRate=21.70\tGlobalRate=23.69\n",
      "[xla:5](80)\tLoss=1.018\tRate=21.70\tGlobalRate=23.69\n",
      "[xla:4](120)\tLoss=0.758\tRate=23.00\tGlobalRate=23.76\n",
      "[xla:7](120)\tLoss=1.177\tRate=23.00\tGlobalRate=23.76\n",
      "[xla:5](120)\tLoss=1.129\tRate=22.99\tGlobalRate=23.75\n",
      "[xla:2](120)\tLoss=0.745\tRate=22.99\tGlobalRate=23.75\n",
      "[xla:3](120)\tLoss=0.391\tRate=23.00\tGlobalRate=23.75\n",
      "[xla:1](120)\tLoss=1.079\tRate=22.99\tGlobalRate=23.75\n",
      "[xla:0](120)\tLoss=1.019\tRate=23.00\tGlobalRate=23.75\n",
      "[xla:6](120)\tLoss=0.516\tRate=23.00\tGlobalRate=23.75\n",
      "[xla:0] Accuracy=74.37%\n",
      "[xla:2] Accuracy=74.51%\n",
      "[xla:5] Accuracy=74.17%\n",
      "[xla:1] Accuracy=74.61%\n",
      "Finished training epoch 4 train-acc 74.37 in 83.59 sec\n",
      "[xla:7] Accuracy=72.02%\n",
      "[xla:6] Accuracy=74.80%\n",
      "[xla:4] Accuracy=74.27%\n",
      "[xla:3] Accuracy=73.63%\n",
      "[xla:3](0)\tLoss=0.506\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:0](0)\tLoss=0.983\tRate=5.81\tGlobalRate=5.81\n",
      "[xla:7](0)\tLoss=0.791\tRate=5.75\tGlobalRate=5.75\n",
      "[xla:5](0)\tLoss=1.441\tRate=5.75\tGlobalRate=5.75\n",
      "[xla:4](0)\tLoss=1.180\tRate=5.75\tGlobalRate=5.75\n",
      "[xla:6](0)\tLoss=1.197\tRate=5.77\tGlobalRate=5.77\n",
      "[xla:1](0)\tLoss=1.477\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:2](0)\tLoss=0.864\tRate=5.77\tGlobalRate=5.77\n",
      "[xla:0](40)\tLoss=1.177\tRate=17.10\tGlobalRate=22.82\n",
      "[xla:7](40)\tLoss=0.832\tRate=17.07\tGlobalRate=22.80\n",
      "[xla:5](40)\tLoss=1.177\tRate=17.07\tGlobalRate=22.80\n",
      "[xla:1](40)\tLoss=1.128\tRate=17.09\tGlobalRate=22.81\n",
      "[xla:4](40)\tLoss=0.984\tRate=17.07\tGlobalRate=22.80\n",
      "[xla:6](40)\tLoss=0.951\tRate=17.08\tGlobalRate=22.80\n",
      "[xla:2](40)\tLoss=0.871\tRate=17.08\tGlobalRate=22.80\n",
      "[xla:3](40)\tLoss=0.729\tRate=17.09\tGlobalRate=22.81\n",
      "[xla:1](80)\tLoss=0.666\tRate=21.01\tGlobalRate=23.20\n",
      "[xla:6](80)\tLoss=0.421\tRate=21.00\tGlobalRate=23.20\n",
      "[xla:2](80)\tLoss=0.524\tRate=21.00\tGlobalRate=23.20\n",
      "[xla:4](80)\tLoss=0.667\tRate=21.00\tGlobalRate=23.19\n",
      "[xla:0](80)\tLoss=0.512\tRate=21.01\tGlobalRate=23.21\n",
      "[xla:7](80)\tLoss=0.560\tRate=21.00\tGlobalRate=23.19\n",
      "[xla:3](80)\tLoss=1.063\tRate=21.01\tGlobalRate=23.20\n",
      "[xla:5](80)\tLoss=0.707\tRate=21.00\tGlobalRate=23.19\n",
      "[xla:6](120)\tLoss=0.372\tRate=23.76\tGlobalRate=23.94\n",
      "[xla:2](120)\tLoss=0.595\tRate=23.76\tGlobalRate=23.94\n",
      "[xla:4](120)\tLoss=0.741\tRate=23.75\tGlobalRate=23.93\n",
      "[xla:1](120)\tLoss=0.763\tRate=23.76\tGlobalRate=23.94\n",
      "[xla:0](120)\tLoss=0.669\tRate=23.75\tGlobalRate=23.94\n",
      "[xla:7](120)\tLoss=0.929\tRate=23.75\tGlobalRate=23.93\n",
      "[xla:5](120)\tLoss=0.684\tRate=23.75\tGlobalRate=23.93\n",
      "[xla:3](120)\tLoss=0.457\tRate=23.75\tGlobalRate=23.94\n",
      "[xla:0] Accuracy=80.27%\n",
      "[xla:6] Accuracy=82.57%\n",
      "[xla:3] Accuracy=79.88%\n",
      "[xla:1] Accuracy=80.81%\n",
      "Finished training epoch 5 train-acc 80.27 in 83.07 sec\n",
      "[xla:5] Accuracy=79.83%\n",
      "[xla:2] Accuracy=82.52%\n",
      "[xla:7] Accuracy=80.13%\n",
      "[xla:4] Accuracy=80.66%\n",
      "[xla:5](0)\tLoss=0.858\tRate=5.81\tGlobalRate=5.81\n",
      "[xla:4](0)\tLoss=0.991\tRate=5.77\tGlobalRate=5.77\n",
      "[xla:2](0)\tLoss=0.447\tRate=5.83\tGlobalRate=5.83\n",
      "[xla:1](0)\tLoss=0.617\tRate=5.78\tGlobalRate=5.78\n",
      "[xla:7](0)\tLoss=0.436\tRate=5.84\tGlobalRate=5.84\n",
      "[xla:6](0)\tLoss=0.554\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:3](0)\tLoss=0.664\tRate=5.78\tGlobalRate=5.78\n",
      "[xla:0](0)\tLoss=1.198\tRate=5.83\tGlobalRate=5.83\n",
      "[xla:5](40)\tLoss=1.213\tRate=16.77\tGlobalRate=22.36\n",
      "[xla:7](40)\tLoss=0.537\tRate=16.78\tGlobalRate=22.37\n",
      "[xla:0](40)\tLoss=0.681\tRate=16.78\tGlobalRate=22.37\n",
      "[xla:1](40)\tLoss=0.809\tRate=16.76\tGlobalRate=22.35\n",
      "[xla:3](40)\tLoss=0.404\tRate=16.76\tGlobalRate=22.35\n",
      "[xla:4](40)\tLoss=0.570\tRate=16.75\tGlobalRate=22.35\n",
      "[xla:6](40)\tLoss=0.691\tRate=16.76\tGlobalRate=22.35\n",
      "[xla:2](40)\tLoss=0.829\tRate=16.78\tGlobalRate=22.37\n",
      "[xla:2](80)\tLoss=0.537\tRate=21.62\tGlobalRate=23.53\n",
      "[xla:7](80)\tLoss=0.295\tRate=21.62\tGlobalRate=23.53\n",
      "[xla:0](80)\tLoss=0.694\tRate=21.62\tGlobalRate=23.53\n",
      "[xla:5](80)\tLoss=0.900\tRate=21.62\tGlobalRate=23.52\n",
      "[xla:1](80)\tLoss=0.749\tRate=21.61\tGlobalRate=23.52\n",
      "[xla:6](80)\tLoss=0.401\tRate=21.62\tGlobalRate=23.52\n",
      "[xla:4](80)\tLoss=0.697\tRate=21.61\tGlobalRate=23.52\n",
      "[xla:3](80)\tLoss=1.074\tRate=21.61\tGlobalRate=23.52\n",
      "[xla:0](120)\tLoss=1.010\tRate=23.28\tGlobalRate=23.80\n",
      "[xla:2](120)\tLoss=0.535\tRate=23.28\tGlobalRate=23.80\n",
      "[xla:5](120)\tLoss=0.798\tRate=23.27\tGlobalRate=23.80\n",
      "[xla:3](120)\tLoss=0.266\tRate=23.27\tGlobalRate=23.80\n",
      "[xla:6](120)\tLoss=0.806\tRate=23.27\tGlobalRate=23.80\n",
      "[xla:1](120)\tLoss=0.530\tRate=23.27\tGlobalRate=23.80\n",
      "[xla:4](120)\tLoss=0.620\tRate=23.27\tGlobalRate=23.80\n",
      "[xla:7](120)\tLoss=1.000\tRate=23.28\tGlobalRate=23.81\n",
      "[xla:3] Accuracy=84.67%\n",
      "[xla:5] Accuracy=84.23%\n",
      "[xla:4] Accuracy=84.57%\n",
      "[xla:2] Accuracy=85.74%\n",
      "[xla:6] Accuracy=85.25%\n",
      "[xla:7] Accuracy=83.84%\n",
      "[xla:0] Accuracy=84.96%\n",
      "[xla:1] Accuracy=85.40%\n",
      "Finished training epoch 6 train-acc 84.96 in 83.84 sec\n",
      "[xla:3](0)\tLoss=0.341\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:6](0)\tLoss=0.545\tRate=5.53\tGlobalRate=5.53\n",
      "[xla:5](0)\tLoss=0.869\tRate=5.57\tGlobalRate=5.57\n",
      "[xla:1](0)\tLoss=1.031\tRate=5.58\tGlobalRate=5.58\n",
      "[xla:7](0)\tLoss=0.610\tRate=5.57\tGlobalRate=5.57\n",
      "[xla:0](0)\tLoss=0.322\tRate=5.56\tGlobalRate=5.56\n",
      "[xla:4](0)\tLoss=0.806\tRate=5.58\tGlobalRate=5.58\n",
      "[xla:2](0)\tLoss=0.249\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:0](40)\tLoss=0.440\tRate=17.17\tGlobalRate=22.97\n",
      "[xla:2](40)\tLoss=0.619\tRate=17.17\tGlobalRate=22.96\n",
      "[xla:6](40)\tLoss=0.728\tRate=17.16\tGlobalRate=22.95\n",
      "[xla:7](40)\tLoss=0.419\tRate=17.18\tGlobalRate=22.97\n",
      "[xla:1](40)\tLoss=0.726\tRate=17.18\tGlobalRate=22.98\n",
      "[xla:3](40)\tLoss=0.267\tRate=17.17\tGlobalRate=22.96\n",
      "[xla:5](40)\tLoss=0.845\tRate=17.18\tGlobalRate=22.97\n",
      "[xla:4](40)\tLoss=1.157\tRate=17.18\tGlobalRate=22.97\n",
      "[xla:2](80)\tLoss=0.830\tRate=21.63\tGlobalRate=23.75\n",
      "[xla:5](80)\tLoss=0.778\tRate=21.64\tGlobalRate=23.75\n",
      "[xla:0](80)\tLoss=0.318\tRate=21.64\tGlobalRate=23.75\n",
      "[xla:1](80)\tLoss=0.354\tRate=21.64\tGlobalRate=23.75\n",
      "[xla:6](80)\tLoss=0.075\tRate=21.63\tGlobalRate=23.74\n",
      "[xla:4](80)\tLoss=0.335\tRate=21.64\tGlobalRate=23.75\n",
      "[xla:3](80)\tLoss=1.132\tRate=21.63\tGlobalRate=23.75\n",
      "[xla:7](80)\tLoss=0.797\tRate=21.64\tGlobalRate=23.75\n",
      "[xla:2](120)\tLoss=0.302\tRate=23.44\tGlobalRate=24.04\n",
      "[xla:7](120)\tLoss=1.040\tRate=23.45\tGlobalRate=24.04\n",
      "[xla:3](120)\tLoss=0.175\tRate=23.44\tGlobalRate=24.04\n",
      "[xla:4](120)\tLoss=0.538\tRate=23.44\tGlobalRate=24.04\n",
      "[xla:0](120)\tLoss=0.725\tRate=23.44\tGlobalRate=24.04\n",
      "[xla:6](120)\tLoss=0.337\tRate=23.44\tGlobalRate=24.04\n",
      "[xla:5](120)\tLoss=0.414\tRate=23.45\tGlobalRate=24.04\n",
      "[xla:1](120)\tLoss=0.748\tRate=23.45\tGlobalRate=24.04\n",
      "[xla:6] Accuracy=85.89%\n",
      "[xla:5] Accuracy=86.23%\n",
      "[xla:4] Accuracy=86.62%\n",
      "[xla:2] Accuracy=88.28%\n",
      "[xla:0] Accuracy=87.45%\n",
      "Finished training epoch 7 train-acc 87.45 in 83.10 sec\n",
      "[xla:1] Accuracy=87.40%\n",
      "[xla:7] Accuracy=87.30%\n",
      "[xla:3] Accuracy=86.23%\n",
      "[xla:1](0)\tLoss=0.519\tRate=5.73\tGlobalRate=5.73\n",
      "[xla:3](0)\tLoss=0.238\tRate=5.72\tGlobalRate=5.72\n",
      "[xla:7](0)\tLoss=0.480\tRate=5.75\tGlobalRate=5.75\n",
      "[xla:0](0)\tLoss=0.296\tRate=5.80\tGlobalRate=5.80\n",
      "[xla:5](0)\tLoss=0.807\tRate=5.73\tGlobalRate=5.73\n",
      "[xla:4](0)\tLoss=0.178\tRate=5.76\tGlobalRate=5.76\n",
      "[xla:2](0)\tLoss=0.618\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:6](0)\tLoss=0.217\tRate=5.76\tGlobalRate=5.76\n",
      "[xla:5](40)\tLoss=1.007\tRate=16.91\tGlobalRate=22.57\n",
      "[xla:2](40)\tLoss=0.463\tRate=16.93\tGlobalRate=22.60\n",
      "[xla:6](40)\tLoss=0.672\tRate=16.92\tGlobalRate=22.58\n",
      "[xla:1](40)\tLoss=0.281\tRate=16.91\tGlobalRate=22.57\n",
      "[xla:7](40)\tLoss=0.522\tRate=16.92\tGlobalRate=22.58\n",
      "[xla:0](40)\tLoss=0.279\tRate=16.94\tGlobalRate=22.60\n",
      "[xla:3](40)\tLoss=0.162\tRate=16.91\tGlobalRate=22.57\n",
      "[xla:4](40)\tLoss=0.784\tRate=16.92\tGlobalRate=22.58\n",
      "[xla:7](80)\tLoss=0.546\tRate=21.57\tGlobalRate=23.57\n",
      "[xla:4](80)\tLoss=0.423\tRate=21.57\tGlobalRate=23.57\n",
      "[xla:1](80)\tLoss=0.242\tRate=21.56\tGlobalRate=23.56\n",
      "[xla:2](80)\tLoss=0.233\tRate=21.58\tGlobalRate=23.58\n",
      "[xla:3](80)\tLoss=0.664\tRate=21.56\tGlobalRate=23.56\n",
      "[xla:6](80)\tLoss=0.424\tRate=21.57\tGlobalRate=23.57\n",
      "[xla:5](80)\tLoss=0.149\tRate=21.56\tGlobalRate=23.56\n",
      "[xla:0](80)\tLoss=0.400\tRate=21.57\tGlobalRate=23.57\n",
      "[xla:5](120)\tLoss=0.466\tRate=23.62\tGlobalRate=24.01\n",
      "[xla:4](120)\tLoss=0.328\tRate=23.62\tGlobalRate=24.02\n",
      "[xla:2](120)\tLoss=0.298\tRate=23.62\tGlobalRate=24.02\n",
      "[xla:7](120)\tLoss=0.312\tRate=23.62\tGlobalRate=24.02\n",
      "[xla:0](120)\tLoss=0.304\tRate=23.63\tGlobalRate=24.03\n",
      "[xla:1](120)\tLoss=0.494\tRate=23.62\tGlobalRate=24.02\n",
      "[xla:6](120)\tLoss=0.201\tRate=23.62\tGlobalRate=24.02\n",
      "[xla:3](120)\tLoss=0.078\tRate=23.62\tGlobalRate=24.01\n",
      "[xla:3] Accuracy=89.40%\n",
      "[xla:1] Accuracy=89.79%\n",
      "[xla:6] Accuracy=88.87%\n",
      "[xla:2] Accuracy=90.28%\n",
      "[xla:0] Accuracy=90.82%\n",
      "[xla:7] Accuracy=89.16%\n",
      "[xla:4] Accuracy=89.60%\n",
      "[xla:5] Accuracy=88.23%\n",
      "Finished training epoch 8 train-acc 90.82 in 82.89 sec\n",
      "[xla:3](0)\tLoss=0.159\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:7](0)\tLoss=0.407\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:1](0)\tLoss=0.461\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:2](0)\tLoss=0.457\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:4](0)\tLoss=0.412\tRate=5.47\tGlobalRate=5.47\n",
      "[xla:0](0)\tLoss=0.488\tRate=5.51\tGlobalRate=5.51\n",
      "[xla:5](0)\tLoss=0.510\tRate=5.49\tGlobalRate=5.49\n",
      "[xla:6](0)\tLoss=0.302\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:7](40)\tLoss=0.120\tRate=16.97\tGlobalRate=22.69\n",
      "[xla:3](40)\tLoss=0.310\tRate=16.99\tGlobalRate=22.71\n",
      "[xla:0](40)\tLoss=0.647\tRate=16.98\tGlobalRate=22.70\n",
      "[xla:4](40)\tLoss=0.127\tRate=16.96\tGlobalRate=22.68\n",
      "[xla:6](40)\tLoss=0.535\tRate=16.96\tGlobalRate=22.68\n",
      "[xla:1](40)\tLoss=0.606\tRate=16.99\tGlobalRate=22.71\n",
      "[xla:2](40)\tLoss=0.281\tRate=16.97\tGlobalRate=22.69\n",
      "[xla:5](40)\tLoss=0.367\tRate=16.96\tGlobalRate=22.69\n",
      "[xla:1](80)\tLoss=0.680\tRate=21.49\tGlobalRate=23.56\n",
      "[xla:6](80)\tLoss=0.238\tRate=21.48\tGlobalRate=23.54\n",
      "[xla:7](80)\tLoss=0.148\tRate=21.48\tGlobalRate=23.55\n",
      "[xla:3](80)\tLoss=0.212\tRate=21.49\tGlobalRate=23.56\n",
      "[xla:2](80)\tLoss=0.351\tRate=21.48\tGlobalRate=23.55\n",
      "[xla:0](80)\tLoss=0.211\tRate=21.48\tGlobalRate=23.55\n",
      "[xla:4](80)\tLoss=0.465\tRate=21.48\tGlobalRate=23.54\n",
      "[xla:5](80)\tLoss=0.449\tRate=21.48\tGlobalRate=23.54\n",
      "[xla:0](120)\tLoss=0.383\tRate=23.29\tGlobalRate=23.85\n",
      "[xla:3](120)\tLoss=0.211\tRate=23.29\tGlobalRate=23.86\n",
      "[xla:6](120)\tLoss=0.647\tRate=23.28\tGlobalRate=23.85\n",
      "[xla:1](120)\tLoss=0.446\tRate=23.28\tGlobalRate=23.86\n",
      "[xla:5](120)\tLoss=0.253\tRate=23.28\tGlobalRate=23.84\n",
      "[xla:4](120)\tLoss=0.215\tRate=23.28\tGlobalRate=23.84\n",
      "[xla:2](120)\tLoss=0.328\tRate=23.28\tGlobalRate=23.85\n",
      "[xla:7](120)\tLoss=0.733\tRate=23.28\tGlobalRate=23.84\n",
      "[xla:1] Accuracy=91.02%\n",
      "[xla:0] Accuracy=91.55%\n",
      "[xla:6] Accuracy=90.62%\n",
      "[xla:3] Accuracy=92.19%\n",
      "[xla:7] Accuracy=91.41%\n",
      "[xla:4] Accuracy=91.50%\n",
      "Finished training epoch 9 train-acc 91.55 in 83.32 sec\n",
      "[xla:2] Accuracy=91.36%\n",
      "[xla:5] Accuracy=91.70%\n",
      "[xla:0](0)\tLoss=0.272\tRate=5.82\tGlobalRate=5.82\n",
      "[xla:2](0)\tLoss=0.269\tRate=5.78\tGlobalRate=5.78\n",
      "[xla:7](0)\tLoss=0.213\tRate=5.77\tGlobalRate=5.77\n",
      "[xla:6](0)\tLoss=0.270\tRate=5.76\tGlobalRate=5.76\n",
      "[xla:3](0)\tLoss=0.460\tRate=5.73\tGlobalRate=5.73\n",
      "[xla:1](0)\tLoss=0.413\tRate=5.73\tGlobalRate=5.73\n",
      "[xla:4](0)\tLoss=0.232\tRate=5.78\tGlobalRate=5.78\n",
      "[xla:5](0)\tLoss=0.237\tRate=5.73\tGlobalRate=5.73\n",
      "[xla:5](40)\tLoss=0.376\tRate=17.18\tGlobalRate=22.95\n",
      "[xla:3](40)\tLoss=0.231\tRate=17.18\tGlobalRate=22.95\n",
      "[xla:1](40)\tLoss=0.265\tRate=17.18\tGlobalRate=22.95\n",
      "[xla:7](40)\tLoss=0.261\tRate=17.20\tGlobalRate=22.96\n",
      "[xla:6](40)\tLoss=0.575\tRate=17.19\tGlobalRate=22.96\n",
      "[xla:4](40)\tLoss=0.415\tRate=17.20\tGlobalRate=22.97\n",
      "[xla:0](40)\tLoss=0.520\tRate=17.22\tGlobalRate=22.99\n",
      "[xla:2](40)\tLoss=0.312\tRate=17.20\tGlobalRate=22.97\n",
      "[xla:4](80)\tLoss=0.384\tRate=21.32\tGlobalRate=23.50\n",
      "[xla:5](80)\tLoss=0.445\tRate=21.32\tGlobalRate=23.49\n",
      "[xla:1](80)\tLoss=0.346\tRate=21.31\tGlobalRate=23.49\n",
      "[xla:3](80)\tLoss=0.276\tRate=21.32\tGlobalRate=23.49\n",
      "[xla:2](80)\tLoss=0.479\tRate=21.32\tGlobalRate=23.50\n",
      "[xla:0](80)\tLoss=0.229\tRate=21.33\tGlobalRate=23.51\n",
      "[xla:6](80)\tLoss=0.373\tRate=21.32\tGlobalRate=23.50\n",
      "[xla:7](80)\tLoss=0.154\tRate=21.32\tGlobalRate=23.50\n",
      "[xla:1](120)\tLoss=0.319\tRate=23.64\tGlobalRate=24.02\n",
      "[xla:3](120)\tLoss=0.182\tRate=23.64\tGlobalRate=24.02\n",
      "[xla:2](120)\tLoss=0.190\tRate=23.64\tGlobalRate=24.03\n",
      "[xla:7](120)\tLoss=0.476\tRate=23.64\tGlobalRate=24.03\n",
      "[xla:4](120)\tLoss=0.161\tRate=23.64\tGlobalRate=24.03\n",
      "[xla:0](120)\tLoss=0.392\tRate=23.64\tGlobalRate=24.04\n",
      "[xla:6](120)\tLoss=0.040\tRate=23.63\tGlobalRate=24.03\n",
      "[xla:5](120)\tLoss=0.532\tRate=23.63\tGlobalRate=24.02\n",
      "[xla:0] Accuracy=93.46%\n",
      "Finished training epoch 10 train-acc 93.46 in 83.27 sec\n",
      "[xla:5] Accuracy=91.55%\n",
      "[xla:1] Accuracy=93.21%\n",
      "[xla:3] Accuracy=92.43%\n",
      "[xla:7] Accuracy=92.72%\n",
      "[xla:4] Accuracy=91.94%\n",
      "[xla:6] Accuracy=92.29%\n",
      "[xla:2] Accuracy=93.41%\n",
      "[xla:5](0)\tLoss=0.165\tRate=5.42\tGlobalRate=5.42\n",
      "[xla:1](0)\tLoss=0.285\tRate=5.39\tGlobalRate=5.39\n",
      "[xla:7](0)\tLoss=0.352\tRate=5.42\tGlobalRate=5.42\n",
      "[xla:3](0)\tLoss=0.137\tRate=5.41\tGlobalRate=5.41\n",
      "[xla:6](0)\tLoss=0.152\tRate=5.39\tGlobalRate=5.39\n",
      "[xla:2](0)\tLoss=0.672\tRate=5.38\tGlobalRate=5.38\n",
      "[xla:0](0)\tLoss=0.170\tRate=5.44\tGlobalRate=5.44\n",
      "[xla:4](0)\tLoss=0.203\tRate=5.38\tGlobalRate=5.38\n",
      "[xla:4](40)\tLoss=0.222\tRate=16.66\tGlobalRate=22.29\n",
      "[xla:3](40)\tLoss=0.124\tRate=16.68\tGlobalRate=22.30\n",
      "[xla:6](40)\tLoss=0.514\tRate=16.67\tGlobalRate=22.29\n",
      "[xla:5](40)\tLoss=0.522\tRate=16.68\tGlobalRate=22.30\n",
      "[xla:2](40)\tLoss=0.198\tRate=16.66\tGlobalRate=22.29\n",
      "[xla:7](40)\tLoss=0.150\tRate=16.68\tGlobalRate=22.30\n",
      "[xla:0](40)\tLoss=0.242\tRate=16.69\tGlobalRate=22.31\n",
      "[xla:1](40)\tLoss=0.296\tRate=16.66\tGlobalRate=22.29\n",
      "[xla:5](80)\tLoss=0.168\tRate=21.45\tGlobalRate=23.39\n",
      "[xla:4](80)\tLoss=0.244\tRate=21.44\tGlobalRate=23.38\n",
      "[xla:6](80)\tLoss=0.265\tRate=21.44\tGlobalRate=23.39\n",
      "[xla:1](80)\tLoss=0.130\tRate=21.44\tGlobalRate=23.38\n",
      "[xla:0](80)\tLoss=0.122\tRate=21.45\tGlobalRate=23.40\n",
      "[xla:2](80)\tLoss=0.102\tRate=21.44\tGlobalRate=23.38\n",
      "[xla:7](80)\tLoss=0.088\tRate=21.45\tGlobalRate=23.39\n",
      "[xla:3](80)\tLoss=0.719\tRate=21.44\tGlobalRate=23.39\n",
      "[xla:5](120)\tLoss=0.888\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:1](120)\tLoss=0.283\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:7](120)\tLoss=0.422\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:4](120)\tLoss=0.406\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:2](120)\tLoss=0.657\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:6](120)\tLoss=0.396\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:0](120)\tLoss=0.082\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:3](120)\tLoss=0.254\tRate=23.52\tGlobalRate=23.87\n",
      "[xla:6] Accuracy=93.75%\n",
      "[xla:2] Accuracy=93.41%\n",
      "[xla:0] Accuracy=93.70%\n",
      "[xla:1] Accuracy=92.92%\n",
      "[xla:7] Accuracy=92.63%\n",
      "[xla:3] Accuracy=92.77%\n",
      "[xla:5] Accuracy=93.41%\n",
      "[xla:4] Accuracy=93.60%\n",
      "Finished training epoch 11 train-acc 93.70 in 83.24 sec\n",
      "[xla:2](0)\tLoss=0.042\tRate=5.97\tGlobalRate=5.97\n",
      "[xla:6](0)\tLoss=0.213\tRate=5.96\tGlobalRate=5.96\n",
      "[xla:0](0)\tLoss=0.338\tRate=5.91\tGlobalRate=5.91\n",
      "[xla:7](0)\tLoss=0.230\tRate=5.95\tGlobalRate=5.95\n",
      "[xla:4](0)\tLoss=0.089\tRate=5.91\tGlobalRate=5.91\n",
      "[xla:5](0)\tLoss=0.827\tRate=5.89\tGlobalRate=5.89\n",
      "[xla:3](0)\tLoss=0.143\tRate=5.90\tGlobalRate=5.90\n",
      "[xla:1](0)\tLoss=0.449\tRate=5.88\tGlobalRate=5.88\n",
      "[xla:0](40)\tLoss=0.683\tRate=17.12\tGlobalRate=22.84\n",
      "[xla:4](40)\tLoss=0.071\tRate=17.13\tGlobalRate=22.84\n",
      "[xla:3](40)\tLoss=0.630\tRate=17.12\tGlobalRate=22.83\n",
      "[xla:1](40)\tLoss=0.419\tRate=17.11\tGlobalRate=22.83\n",
      "[xla:6](40)\tLoss=0.439\tRate=17.14\tGlobalRate=22.85\n",
      "[xla:5](40)\tLoss=0.272\tRate=17.12\tGlobalRate=22.83\n",
      "[xla:2](40)\tLoss=0.203\tRate=17.15\tGlobalRate=22.86\n",
      "[xla:7](40)\tLoss=0.171\tRate=17.14\tGlobalRate=22.85\n",
      "[xla:4](80)\tLoss=0.119\tRate=21.45\tGlobalRate=23.55\n",
      "[xla:2](80)\tLoss=0.497\tRate=21.46\tGlobalRate=23.56\n",
      "[xla:0](80)\tLoss=0.122\tRate=21.45\tGlobalRate=23.55\n",
      "[xla:5](80)\tLoss=0.287\tRate=21.44\tGlobalRate=23.55\n",
      "[xla:1](80)\tLoss=0.269\tRate=21.44\tGlobalRate=23.54\n",
      "[xla:7](80)\tLoss=0.197\tRate=21.45\tGlobalRate=23.56\n",
      "[xla:6](80)\tLoss=0.076\tRate=21.45\tGlobalRate=23.56\n",
      "[xla:3](80)\tLoss=0.349\tRate=21.44\tGlobalRate=23.54\n",
      "[xla:1](120)\tLoss=0.359\tRate=23.48\tGlobalRate=23.96\n",
      "[xla:5](120)\tLoss=0.278\tRate=23.48\tGlobalRate=23.96\n",
      "[xla:6](120)\tLoss=0.156\tRate=23.49\tGlobalRate=23.97\n",
      "[xla:7](120)\tLoss=0.143\tRate=23.49\tGlobalRate=23.97\n",
      "[xla:4](120)\tLoss=0.218\tRate=23.49\tGlobalRate=23.96\n",
      "[xla:0](120)\tLoss=0.071\tRate=23.48\tGlobalRate=23.96\n",
      "[xla:3](120)\tLoss=0.410\tRate=23.49\tGlobalRate=23.96\n",
      "[xla:2](120)\tLoss=0.018\tRate=23.49\tGlobalRate=23.97\n",
      "[xla:7] Accuracy=93.95%\n",
      "[xla:3] Accuracy=94.19%\n",
      "[xla:4] Accuracy=94.29%\n",
      "[xla:0] Accuracy=93.85%\n",
      "[xla:2] Accuracy=94.14%\n",
      "[xla:1] Accuracy=93.31%\n",
      "Finished training epoch 12 train-acc 93.85 in 83.11 sec\n",
      "[xla:5] Accuracy=93.31%\n",
      "[xla:6] Accuracy=92.92%\n",
      "[xla:5](0)\tLoss=0.250\tRate=5.57\tGlobalRate=5.57\n",
      "[xla:4](0)\tLoss=0.235\tRate=5.53\tGlobalRate=5.53\n",
      "[xla:2](0)\tLoss=0.120\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:7](0)\tLoss=0.183\tRate=5.53\tGlobalRate=5.53\n",
      "[xla:6](0)\tLoss=0.200\tRate=5.57\tGlobalRate=5.57\n",
      "[xla:0](0)\tLoss=0.160\tRate=5.61\tGlobalRate=5.61\n",
      "[xla:3](0)\tLoss=0.348\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:1](0)\tLoss=0.483\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:2](40)\tLoss=0.207\tRate=16.49\tGlobalRate=22.01\n",
      "[xla:6](40)\tLoss=0.342\tRate=16.49\tGlobalRate=22.02\n",
      "[xla:3](40)\tLoss=0.255\tRate=16.49\tGlobalRate=22.02\n",
      "[xla:1](40)\tLoss=0.226\tRate=16.48\tGlobalRate=22.01\n",
      "[xla:5](40)\tLoss=0.309\tRate=16.49\tGlobalRate=22.02\n",
      "[xla:4](40)\tLoss=0.083\tRate=16.48\tGlobalRate=22.01\n",
      "[xla:7](40)\tLoss=0.148\tRate=16.48\tGlobalRate=22.01\n",
      "[xla:0](40)\tLoss=0.223\tRate=16.51\tGlobalRate=22.03\n",
      "[xla:4](80)\tLoss=0.249\tRate=21.22\tGlobalRate=23.12\n",
      "[xla:7](80)\tLoss=0.050\tRate=21.22\tGlobalRate=23.12\n",
      "[xla:5](80)\tLoss=0.087\tRate=21.23\tGlobalRate=23.13\n",
      "[xla:6](80)\tLoss=0.070\tRate=21.23\tGlobalRate=23.13\n",
      "[xla:2](80)\tLoss=0.272\tRate=21.22\tGlobalRate=23.12\n",
      "[xla:0](80)\tLoss=0.145\tRate=21.23\tGlobalRate=23.13\n",
      "[xla:1](80)\tLoss=0.093\tRate=21.22\tGlobalRate=23.12\n",
      "[xla:3](80)\tLoss=0.148\tRate=21.22\tGlobalRate=23.12\n",
      "[xla:2](120)\tLoss=0.137\tRate=23.55\tGlobalRate=23.74\n",
      "[xla:0](120)\tLoss=0.253\tRate=23.55\tGlobalRate=23.75\n",
      "[xla:1](120)\tLoss=0.188\tRate=23.55\tGlobalRate=23.74\n",
      "[xla:6](120)\tLoss=0.065\tRate=23.55\tGlobalRate=23.74\n",
      "[xla:3](120)\tLoss=0.023\tRate=23.55\tGlobalRate=23.74\n",
      "[xla:4](120)\tLoss=0.632\tRate=23.54\tGlobalRate=23.74\n",
      "[xla:7](120)\tLoss=0.314\tRate=23.54\tGlobalRate=23.74\n",
      "[xla:5](120)\tLoss=0.125\tRate=23.55\tGlobalRate=23.74\n",
      "[xla:5] Accuracy=95.21%\n",
      "[xla:2] Accuracy=93.60%\n",
      "[xla:3] Accuracy=93.75%\n",
      "[xla:6] Accuracy=94.24%\n",
      "[xla:4] Accuracy=95.17%\n",
      "[xla:0] Accuracy=93.26%\n",
      "[xla:7] Accuracy=95.17%\n",
      "Finished training epoch 13 train-acc 93.26 in 83.70 sec\n",
      "[xla:1] Accuracy=94.53%\n",
      "[xla:1](0)\tLoss=0.371\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:5](0)\tLoss=0.302\tRate=5.47\tGlobalRate=5.47\n",
      "[xla:3](0)\tLoss=0.199\tRate=5.48\tGlobalRate=5.48\n",
      "[xla:6](0)\tLoss=0.165\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:4](0)\tLoss=0.242\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:0](0)\tLoss=0.098\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:2](0)\tLoss=0.199\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:7](0)\tLoss=0.056\tRate=5.49\tGlobalRate=5.49\n",
      "[xla:3](40)\tLoss=0.180\tRate=16.87\tGlobalRate=22.56\n",
      "[xla:4](40)\tLoss=0.161\tRate=16.89\tGlobalRate=22.58\n",
      "[xla:7](40)\tLoss=0.448\tRate=16.88\tGlobalRate=22.57\n",
      "[xla:2](40)\tLoss=0.047\tRate=16.90\tGlobalRate=22.59\n",
      "[xla:5](40)\tLoss=0.587\tRate=16.87\tGlobalRate=22.56\n",
      "[xla:6](40)\tLoss=0.223\tRate=16.88\tGlobalRate=22.57\n",
      "[xla:0](40)\tLoss=0.186\tRate=16.89\tGlobalRate=22.58\n",
      "[xla:1](40)\tLoss=0.402\tRate=16.89\tGlobalRate=22.58\n",
      "[xla:7](80)\tLoss=0.055\tRate=21.67\tGlobalRate=23.64\n",
      "[xla:3](80)\tLoss=0.702\tRate=21.67\tGlobalRate=23.64\n",
      "[xla:6](80)\tLoss=0.105\tRate=21.67\tGlobalRate=23.65\n",
      "[xla:0](80)\tLoss=0.182\tRate=21.67\tGlobalRate=23.65\n",
      "[xla:2](80)\tLoss=0.502\tRate=21.68\tGlobalRate=23.66\n",
      "[xla:1](80)\tLoss=0.177\tRate=21.67\tGlobalRate=23.65\n",
      "[xla:4](80)\tLoss=0.034\tRate=21.67\tGlobalRate=23.65\n",
      "[xla:5](80)\tLoss=0.341\tRate=21.66\tGlobalRate=23.64\n",
      "[xla:4](120)\tLoss=0.298\tRate=23.22\tGlobalRate=23.84\n",
      "[xla:0](120)\tLoss=0.206\tRate=23.22\tGlobalRate=23.85\n",
      "[xla:5](120)\tLoss=0.231\tRate=23.22\tGlobalRate=23.84\n",
      "[xla:1](120)\tLoss=0.089\tRate=23.22\tGlobalRate=23.85\n",
      "[xla:3](120)\tLoss=0.509\tRate=23.22\tGlobalRate=23.84\n",
      "[xla:6](120)\tLoss=0.256\tRate=23.22\tGlobalRate=23.84\n",
      "[xla:2](120)\tLoss=0.299\tRate=23.22\tGlobalRate=23.85\n",
      "[xla:7](120)\tLoss=0.371\tRate=23.22\tGlobalRate=23.84\n",
      "[xla:2] Accuracy=95.75%\n",
      "[xla:5] Accuracy=94.38%\n",
      "[xla:7] Accuracy=95.65%\n",
      "[xla:1] Accuracy=94.97%\n",
      "[xla:0] Accuracy=95.17%\n",
      "[xla:3] Accuracy=94.53%\n",
      "[xla:4] Accuracy=95.17%\n",
      "Finished training epoch 14 train-acc 95.17 in 83.63 sec\n",
      "[xla:6] Accuracy=95.26%\n",
      "[xla:4](0)\tLoss=0.085\tRate=5.51\tGlobalRate=5.51\n",
      "[xla:1](0)\tLoss=0.050\tRate=5.48\tGlobalRate=5.48\n",
      "[xla:0](0)\tLoss=0.109\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:2](0)\tLoss=0.422\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:5](0)\tLoss=0.232\tRate=5.48\tGlobalRate=5.48\n",
      "[xla:6](0)\tLoss=0.117\tRate=5.47\tGlobalRate=5.47\n",
      "[xla:7](0)\tLoss=0.047\tRate=5.49\tGlobalRate=5.49\n",
      "[xla:3](0)\tLoss=0.021\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:2](40)\tLoss=0.157\tRate=16.96\tGlobalRate=22.68\n",
      "[xla:1](40)\tLoss=0.784\tRate=16.95\tGlobalRate=22.67\n",
      "[xla:6](40)\tLoss=0.197\tRate=16.95\tGlobalRate=22.66\n",
      "[xla:3](40)\tLoss=0.172\tRate=16.96\tGlobalRate=22.68\n",
      "[xla:4](40)\tLoss=0.180\tRate=16.96\tGlobalRate=22.68\n",
      "[xla:0](40)\tLoss=0.257\tRate=16.98\tGlobalRate=22.70\n",
      "[xla:7](40)\tLoss=0.029\tRate=16.95\tGlobalRate=22.67\n",
      "[xla:5](40)\tLoss=0.133\tRate=16.94\tGlobalRate=22.66\n",
      "[xla:6](80)\tLoss=0.169\tRate=21.12\tGlobalRate=23.26\n",
      "[xla:3](80)\tLoss=0.149\tRate=21.12\tGlobalRate=23.26\n",
      "[xla:5](80)\tLoss=0.164\tRate=21.12\tGlobalRate=23.26\n",
      "[xla:0](80)\tLoss=0.106\tRate=21.13\tGlobalRate=23.28\n",
      "[xla:2](80)\tLoss=0.060\tRate=21.12\tGlobalRate=23.26\n",
      "[xla:7](80)\tLoss=0.103\tRate=21.12\tGlobalRate=23.26\n",
      "[xla:4](80)\tLoss=0.025\tRate=21.12\tGlobalRate=23.27\n",
      "[xla:1](80)\tLoss=0.269\tRate=21.12\tGlobalRate=23.26\n",
      "[xla:7](120)\tLoss=0.256\tRate=23.52\tGlobalRate=23.85\n",
      "[xla:4](120)\tLoss=0.021\tRate=23.52\tGlobalRate=23.85\n",
      "[xla:0](120)\tLoss=0.266\tRate=23.52\tGlobalRate=23.85\n",
      "[xla:5](120)\tLoss=0.136\tRate=23.52\tGlobalRate=23.84\n",
      "[xla:1](120)\tLoss=0.372\tRate=23.52\tGlobalRate=23.84\n",
      "[xla:2](120)\tLoss=0.401\tRate=23.52\tGlobalRate=23.85\n",
      "[xla:3](120)\tLoss=0.020\tRate=23.52\tGlobalRate=23.85\n",
      "[xla:6](120)\tLoss=0.237\tRate=23.52\tGlobalRate=23.84\n",
      "[xla:3] Accuracy=95.56%\n",
      "[xla:6] Accuracy=95.31%\n",
      "[xla:7] Accuracy=94.97%\n",
      "[xla:4] Accuracy=96.04%\n",
      "[xla:5] Accuracy=96.00%\n",
      "[xla:0] Accuracy=96.14%\n",
      "[xla:2] Accuracy=95.26%\n",
      "[xla:1] Accuracy=94.87%\n",
      "Finished training epoch 15 train-acc 96.14 in 83.26 sec\n",
      "[xla:7](0)\tLoss=0.048\tRate=5.68\tGlobalRate=5.68\n",
      "[xla:0](0)\tLoss=0.341\tRate=5.74\tGlobalRate=5.74\n",
      "[xla:5](0)\tLoss=0.374\tRate=5.72\tGlobalRate=5.72\n",
      "[xla:1](0)\tLoss=0.201\tRate=5.66\tGlobalRate=5.66\n",
      "[xla:3](0)\tLoss=0.069\tRate=5.67\tGlobalRate=5.67\n",
      "[xla:6](0)\tLoss=0.181\tRate=5.66\tGlobalRate=5.66\n",
      "[xla:4](0)\tLoss=0.106\tRate=5.65\tGlobalRate=5.65\n",
      "[xla:2](0)\tLoss=0.047\tRate=5.68\tGlobalRate=5.68\n",
      "[xla:0](40)\tLoss=0.045\tRate=16.68\tGlobalRate=22.24\n",
      "[xla:7](40)\tLoss=0.033\tRate=16.65\tGlobalRate=22.22\n",
      "[xla:1](40)\tLoss=0.084\tRate=16.64\tGlobalRate=22.21\n",
      "[xla:5](40)\tLoss=0.116\tRate=16.67\tGlobalRate=22.24\n",
      "[xla:2](40)\tLoss=0.107\tRate=16.65\tGlobalRate=22.23\n",
      "[xla:3](40)\tLoss=0.181\tRate=16.65\tGlobalRate=22.22\n",
      "[xla:4](40)\tLoss=0.109\tRate=16.64\tGlobalRate=22.21\n",
      "[xla:6](40)\tLoss=0.036\tRate=16.64\tGlobalRate=22.21\n",
      "[xla:7](80)\tLoss=0.086\tRate=21.61\tGlobalRate=23.47\n",
      "[xla:5](80)\tLoss=0.081\tRate=21.61\tGlobalRate=23.48\n",
      "[xla:0](80)\tLoss=0.087\tRate=21.61\tGlobalRate=23.48\n",
      "[xla:3](80)\tLoss=0.203\tRate=21.61\tGlobalRate=23.47\n",
      "[xla:2](80)\tLoss=0.114\tRate=21.61\tGlobalRate=23.48\n",
      "[xla:4](80)\tLoss=0.097\tRate=21.60\tGlobalRate=23.47\n",
      "[xla:6](80)\tLoss=0.378\tRate=21.60\tGlobalRate=23.47\n",
      "[xla:1](80)\tLoss=0.128\tRate=21.60\tGlobalRate=23.47\n",
      "[xla:0](120)\tLoss=0.036\tRate=23.31\tGlobalRate=23.79\n",
      "[xla:6](120)\tLoss=0.152\tRate=23.30\tGlobalRate=23.78\n",
      "[xla:4](120)\tLoss=0.024\tRate=23.30\tGlobalRate=23.78\n",
      "[xla:5](120)\tLoss=0.149\tRate=23.31\tGlobalRate=23.79\n",
      "[xla:3](120)\tLoss=0.224\tRate=23.30\tGlobalRate=23.78\n",
      "[xla:1](120)\tLoss=0.048\tRate=23.30\tGlobalRate=23.78\n",
      "[xla:2](120)\tLoss=0.096\tRate=23.30\tGlobalRate=23.78\n",
      "[xla:7](120)\tLoss=0.676\tRate=23.30\tGlobalRate=23.78\n",
      "[xla:4] Accuracy=96.48%\n",
      "[xla:3] Accuracy=95.61%\n",
      "[xla:1] Accuracy=96.58%\n",
      "[xla:0] Accuracy=95.95%\n",
      "[xla:5] Accuracy=95.70%\n",
      "[xla:7] Accuracy=94.97%\n",
      "[xla:6] Accuracy=95.65%\n",
      "Finished training epoch 16 train-acc 95.95 in 83.74 sec\n",
      "[xla:2] Accuracy=95.90%\n",
      "[xla:3](0)\tLoss=0.049\tRate=5.91\tGlobalRate=5.91\n",
      "[xla:6](0)\tLoss=0.132\tRate=5.94\tGlobalRate=5.94\n",
      "[xla:4](0)\tLoss=0.109\tRate=5.96\tGlobalRate=5.96\n",
      "[xla:7](0)\tLoss=0.157\tRate=5.89\tGlobalRate=5.89\n",
      "[xla:0](0)\tLoss=0.081\tRate=5.96\tGlobalRate=5.96\n",
      "[xla:1](0)\tLoss=0.281\tRate=5.90\tGlobalRate=5.90\n",
      "[xla:5](0)\tLoss=0.037\tRate=5.91\tGlobalRate=5.91\n",
      "[xla:2](0)\tLoss=0.023\tRate=5.95\tGlobalRate=5.95\n",
      "[xla:1](40)\tLoss=0.159\tRate=17.39\tGlobalRate=23.21\n",
      "[xla:2](40)\tLoss=0.115\tRate=17.41\tGlobalRate=23.23\n",
      "[xla:6](40)\tLoss=0.113\tRate=17.40\tGlobalRate=23.22\n",
      "[xla:3](40)\tLoss=0.017\tRate=17.39\tGlobalRate=23.21\n",
      "[xla:5](40)\tLoss=0.186\tRate=17.39\tGlobalRate=23.21\n",
      "[xla:4](40)\tLoss=0.030\tRate=17.41\tGlobalRate=23.23\n",
      "[xla:0](40)\tLoss=0.231\tRate=17.41\tGlobalRate=23.23\n",
      "[xla:7](40)\tLoss=0.139\tRate=17.38\tGlobalRate=23.20\n",
      "[xla:3](80)\tLoss=0.304\tRate=21.25\tGlobalRate=23.51\n",
      "[xla:1](80)\tLoss=0.130\tRate=21.25\tGlobalRate=23.51\n",
      "[xla:4](80)\tLoss=0.141\tRate=21.26\tGlobalRate=23.52\n",
      "[xla:0](80)\tLoss=0.078\tRate=21.26\tGlobalRate=23.52\n",
      "[xla:7](80)\tLoss=0.013\tRate=21.25\tGlobalRate=23.51\n",
      "[xla:6](80)\tLoss=0.143\tRate=21.25\tGlobalRate=23.52\n",
      "[xla:2](80)\tLoss=0.284\tRate=21.25\tGlobalRate=23.52\n",
      "[xla:5](80)\tLoss=0.097\tRate=21.25\tGlobalRate=23.51\n",
      "[xla:1](120)\tLoss=0.044\tRate=23.54\tGlobalRate=24.00\n",
      "[xla:6](120)\tLoss=0.008\tRate=23.55\tGlobalRate=24.01\n",
      "[xla:7](120)\tLoss=0.174\tRate=23.54\tGlobalRate=24.00\n",
      "[xla:4](120)\tLoss=0.157\tRate=23.55\tGlobalRate=24.01\n",
      "[xla:5](120)\tLoss=0.188\tRate=23.55\tGlobalRate=24.00\n",
      "[xla:3](120)\tLoss=0.019\tRate=23.55\tGlobalRate=24.00\n",
      "[xla:2](120)\tLoss=0.528\tRate=23.55\tGlobalRate=24.01\n",
      "[xla:0](120)\tLoss=0.285\tRate=23.55\tGlobalRate=24.01\n",
      "[xla:6] Accuracy=96.39%\n",
      "[xla:7] Accuracy=96.63%\n",
      "[xla:0] Accuracy=96.19%\n",
      "[xla:1] Accuracy=96.04%\n",
      "[xla:5] Accuracy=96.48%\n",
      "[xla:2] Accuracy=96.58%\n",
      "[xla:4] Accuracy=96.39%\n",
      "Finished training epoch 17 train-acc 96.19 in 82.70 sec\n",
      "[xla:3] Accuracy=96.09%\n",
      "[xla:5](0)\tLoss=0.139\tRate=5.33\tGlobalRate=5.33\n",
      "[xla:6](0)\tLoss=0.052\tRate=5.35\tGlobalRate=5.35\n",
      "[xla:3](0)\tLoss=0.185\tRate=5.32\tGlobalRate=5.32\n",
      "[xla:0](0)\tLoss=0.068\tRate=5.35\tGlobalRate=5.35\n",
      "[xla:1](0)\tLoss=0.219\tRate=5.30\tGlobalRate=5.30\n",
      "[xla:7](0)\tLoss=0.462\tRate=5.30\tGlobalRate=5.30\n",
      "[xla:4](0)\tLoss=0.285\tRate=5.30\tGlobalRate=5.30\n",
      "[xla:2](0)\tLoss=0.198\tRate=5.36\tGlobalRate=5.36\n",
      "[xla:3](40)\tLoss=0.106\tRate=16.73\tGlobalRate=22.39\n",
      "[xla:2](40)\tLoss=0.106\tRate=16.75\tGlobalRate=22.41\n",
      "[xla:6](40)\tLoss=0.106\tRate=16.75\tGlobalRate=22.40\n",
      "[xla:4](40)\tLoss=0.362\tRate=16.72\tGlobalRate=22.38\n",
      "[xla:7](40)\tLoss=0.036\tRate=16.73\tGlobalRate=22.38\n",
      "[xla:1](40)\tLoss=0.084\tRate=16.73\tGlobalRate=22.38\n",
      "[xla:0](40)\tLoss=0.156\tRate=16.75\tGlobalRate=22.40\n",
      "[xla:5](40)\tLoss=0.065\tRate=16.74\tGlobalRate=22.39\n",
      "[xla:3](80)\tLoss=0.097\tRate=21.76\tGlobalRate=23.65\n",
      "[xla:0](80)\tLoss=0.095\tRate=21.76\tGlobalRate=23.66\n",
      "[xla:2](80)\tLoss=0.124\tRate=21.76\tGlobalRate=23.66\n",
      "[xla:1](80)\tLoss=0.034\tRate=21.75\tGlobalRate=23.65\n",
      "[xla:4](80)\tLoss=0.077\tRate=21.75\tGlobalRate=23.65\n",
      "[xla:6](80)\tLoss=0.046\tRate=21.76\tGlobalRate=23.66\n",
      "[xla:7](80)\tLoss=0.189\tRate=21.75\tGlobalRate=23.65\n",
      "[xla:5](80)\tLoss=0.341\tRate=21.76\tGlobalRate=23.66\n",
      "[xla:1](120)\tLoss=0.067\tRate=23.67\tGlobalRate=24.06\n",
      "[xla:4](120)\tLoss=0.032\tRate=23.67\tGlobalRate=24.06\n",
      "[xla:2](120)\tLoss=0.057\tRate=23.67\tGlobalRate=24.07\n",
      "[xla:3](120)\tLoss=0.121\tRate=23.67\tGlobalRate=24.07\n",
      "[xla:5](120)\tLoss=0.383\tRate=23.67\tGlobalRate=24.07\n",
      "[xla:6](120)\tLoss=0.159\tRate=23.68\tGlobalRate=24.07\n",
      "[xla:0](120)\tLoss=0.208\tRate=23.67\tGlobalRate=24.07\n",
      "[xla:7](120)\tLoss=0.102\tRate=23.67\tGlobalRate=24.06\n",
      "[xla:2] Accuracy=96.73%\n",
      "[xla:4] Accuracy=96.24%\n",
      "[xla:0] Accuracy=96.19%\n",
      "[xla:5] Accuracy=96.29%\n",
      "[xla:1] Accuracy=96.19%\n",
      "[xla:7] Accuracy=96.19%\n",
      "[xla:6] Accuracy=96.88%\n",
      "[xla:3] Accuracy=96.29%\n",
      "Finished training epoch 18 train-acc 96.19 in 83.06 sec\n",
      "[xla:1](0)\tLoss=0.059\tRate=5.36\tGlobalRate=5.36\n",
      "[xla:4](0)\tLoss=0.026\tRate=5.37\tGlobalRate=5.37\n",
      "[xla:0](0)\tLoss=0.224\tRate=5.37\tGlobalRate=5.37\n",
      "[xla:6](0)\tLoss=0.082\tRate=5.34\tGlobalRate=5.34\n",
      "[xla:3](0)\tLoss=0.027\tRate=5.34\tGlobalRate=5.34\n",
      "[xla:7](0)\tLoss=0.212\tRate=5.36\tGlobalRate=5.36\n",
      "[xla:2](0)\tLoss=0.235\tRate=5.32\tGlobalRate=5.32\n",
      "[xla:5](0)\tLoss=0.114\tRate=5.31\tGlobalRate=5.31\n",
      "[xla:1](40)\tLoss=0.072\tRate=16.99\tGlobalRate=22.73\n",
      "[xla:4](40)\tLoss=0.097\tRate=16.99\tGlobalRate=22.74\n",
      "[xla:3](40)\tLoss=0.051\tRate=16.98\tGlobalRate=22.72\n",
      "[xla:7](40)\tLoss=0.090\tRate=16.99\tGlobalRate=22.73\n",
      "[xla:0](40)\tLoss=0.061\tRate=16.99\tGlobalRate=22.74\n",
      "[xla:2](40)\tLoss=0.078\tRate=16.97\tGlobalRate=22.72\n",
      "[xla:6](40)\tLoss=0.678\tRate=16.98\tGlobalRate=22.72\n",
      "[xla:5](40)\tLoss=0.096\tRate=16.97\tGlobalRate=22.71\n",
      "[xla:0](80)\tLoss=0.163\tRate=21.33\tGlobalRate=23.45\n",
      "[xla:3](80)\tLoss=0.163\tRate=21.33\tGlobalRate=23.44\n",
      "[xla:6](80)\tLoss=0.111\tRate=21.33\tGlobalRate=23.44\n",
      "[xla:5](80)\tLoss=0.354\tRate=21.32\tGlobalRate=23.44\n",
      "[xla:1](80)\tLoss=0.081\tRate=21.33\tGlobalRate=23.45\n",
      "[xla:4](80)\tLoss=0.031\tRate=21.33\tGlobalRate=23.45\n",
      "[xla:7](80)\tLoss=0.041\tRate=21.33\tGlobalRate=23.45\n",
      "[xla:2](80)\tLoss=0.139\tRate=21.33\tGlobalRate=23.44\n",
      "[xla:6](120)\tLoss=0.024\tRate=23.20\tGlobalRate=23.77\n",
      "[xla:2](120)\tLoss=0.103\tRate=23.20\tGlobalRate=23.76\n",
      "[xla:5](120)\tLoss=0.228\tRate=23.19\tGlobalRate=23.76\n",
      "[xla:4](120)\tLoss=0.017\tRate=23.20\tGlobalRate=23.77\n",
      "[xla:7](120)\tLoss=0.190\tRate=23.20\tGlobalRate=23.77\n",
      "[xla:3](120)\tLoss=0.012\tRate=23.19\tGlobalRate=23.76\n",
      "[xla:0](120)\tLoss=0.032\tRate=23.20\tGlobalRate=23.77\n",
      "[xla:1](120)\tLoss=0.435\tRate=23.19\tGlobalRate=23.77\n",
      "[xla:3] Accuracy=96.58%\n",
      "[xla:6] Accuracy=96.24%\n",
      "[xla:0] Accuracy=96.39%\n",
      "[xla:5] Accuracy=96.48%\n",
      "[xla:2] Accuracy=96.73%\n",
      "Finished training epoch 19 train-acc 96.39 in 83.66 sec\n",
      "[xla:1] Accuracy=96.34%\n",
      "[xla:4] Accuracy=96.53%\n",
      "[xla:7] Accuracy=97.02%\n",
      "[xla:5](0)\tLoss=0.082\tRate=5.90\tGlobalRate=5.90\n",
      "[xla:1](0)\tLoss=0.106\tRate=5.85\tGlobalRate=5.85\n",
      "[xla:4](0)\tLoss=0.043\tRate=5.86\tGlobalRate=5.86\n",
      "[xla:0](0)\tLoss=0.045\tRate=5.93\tGlobalRate=5.93\n",
      "[xla:3](0)\tLoss=0.012\tRate=5.90\tGlobalRate=5.90\n",
      "[xla:6](0)\tLoss=0.041\tRate=5.86\tGlobalRate=5.86\n",
      "[xla:7](0)\tLoss=0.042\tRate=5.89\tGlobalRate=5.89\n",
      "[xla:2](0)\tLoss=0.054\tRate=5.87\tGlobalRate=5.87\n",
      "[xla:4](40)\tLoss=0.146\tRate=17.25\tGlobalRate=23.03\n",
      "[xla:7](40)\tLoss=0.020\tRate=17.26\tGlobalRate=23.04\n",
      "[xla:2](40)\tLoss=0.016\tRate=17.26\tGlobalRate=23.04\n",
      "[xla:5](40)\tLoss=0.104\tRate=17.27\tGlobalRate=23.05\n",
      "[xla:3](40)\tLoss=0.024\tRate=17.27\tGlobalRate=23.04\n",
      "[xla:6](40)\tLoss=0.535\tRate=17.25\tGlobalRate=23.03\n",
      "[xla:1](40)\tLoss=0.158\tRate=17.25\tGlobalRate=23.03\n",
      "[xla:0](40)\tLoss=0.245\tRate=17.28\tGlobalRate=23.06\n",
      "[xla:5](80)\tLoss=0.032\tRate=21.46\tGlobalRate=23.63\n",
      "[xla:4](80)\tLoss=0.023\tRate=21.45\tGlobalRate=23.62\n",
      "[xla:7](80)\tLoss=0.071\tRate=21.46\tGlobalRate=23.62\n",
      "[xla:6](80)\tLoss=0.029\tRate=21.45\tGlobalRate=23.62\n",
      "[xla:1](80)\tLoss=0.090\tRate=21.45\tGlobalRate=23.62\n",
      "[xla:3](80)\tLoss=0.235\tRate=21.46\tGlobalRate=23.63\n",
      "[xla:0](80)\tLoss=0.182\tRate=21.46\tGlobalRate=23.63\n",
      "[xla:2](80)\tLoss=0.045\tRate=21.45\tGlobalRate=23.62\n",
      "[xla:5](120)\tLoss=0.046\tRate=23.80\tGlobalRate=24.17\n",
      "[xla:2](120)\tLoss=0.047\tRate=23.80\tGlobalRate=24.17\n",
      "[xla:6](120)\tLoss=0.031\tRate=23.80\tGlobalRate=24.17\n",
      "[xla:1](120)\tLoss=0.066\tRate=23.80\tGlobalRate=24.17\n",
      "[xla:4](120)\tLoss=0.091\tRate=23.80\tGlobalRate=24.17\n",
      "[xla:7](120)\tLoss=0.095\tRate=23.80\tGlobalRate=24.17\n",
      "[xla:3](120)\tLoss=0.011\tRate=23.80\tGlobalRate=24.17\n",
      "[xla:0](120)\tLoss=0.107\tRate=23.81\tGlobalRate=24.18\n",
      "[xla:0] Accuracy=97.41%\n",
      "[xla:1] Accuracy=96.83%\n",
      "Finished training epoch 20 train-acc 97.41 in 82.89 sec\n",
      "[xla:2] Accuracy=97.46%\n",
      "[xla:4] Accuracy=97.22%\n",
      "[xla:3] Accuracy=96.78%\n",
      "[xla:5] Accuracy=96.63%\n",
      "[xla:7] Accuracy=97.27%\n",
      "[xla:6] Accuracy=97.36%\n",
      "[xla:6](0)\tLoss=0.099\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:4](0)\tLoss=0.035\tRate=5.53\tGlobalRate=5.53\n",
      "[xla:2](0)\tLoss=0.024\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:5](0)\tLoss=0.010\tRate=5.47\tGlobalRate=5.47\n",
      "[xla:1](0)\tLoss=0.031\tRate=5.47\tGlobalRate=5.47\n",
      "[xla:3](0)\tLoss=0.105\tRate=5.46\tGlobalRate=5.46\n",
      "[xla:0](0)\tLoss=0.078\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:7](0)\tLoss=0.159\tRate=5.47\tGlobalRate=5.47\n",
      "[xla:6](40)\tLoss=0.366\tRate=16.70\tGlobalRate=22.32\n",
      "[xla:4](40)\tLoss=0.024\tRate=16.71\tGlobalRate=22.33\n",
      "[xla:2](40)\tLoss=0.189\tRate=16.71\tGlobalRate=22.33\n",
      "[xla:7](40)\tLoss=0.030\tRate=16.69\tGlobalRate=22.31\n",
      "[xla:5](40)\tLoss=0.015\tRate=16.69\tGlobalRate=22.31\n",
      "[xla:0](40)\tLoss=0.075\tRate=16.71\tGlobalRate=22.33\n",
      "[xla:1](40)\tLoss=0.019\tRate=16.69\tGlobalRate=22.31\n",
      "[xla:3](40)\tLoss=0.013\tRate=16.69\tGlobalRate=22.31\n",
      "[xla:4](80)\tLoss=0.122\tRate=21.55\tGlobalRate=23.48\n",
      "[xla:0](80)\tLoss=0.195\tRate=21.55\tGlobalRate=23.48\n",
      "[xla:6](80)\tLoss=0.088\tRate=21.55\tGlobalRate=23.47\n",
      "[xla:3](80)\tLoss=0.815\tRate=21.54\tGlobalRate=23.47\n",
      "[xla:1](80)\tLoss=0.033\tRate=21.54\tGlobalRate=23.47\n",
      "[xla:2](80)\tLoss=0.062\tRate=21.55\tGlobalRate=23.48\n",
      "[xla:5](80)\tLoss=0.083\tRate=21.54\tGlobalRate=23.46\n",
      "[xla:7](80)\tLoss=0.019\tRate=21.54\tGlobalRate=23.46\n",
      "[xla:6](120)\tLoss=0.080\tRate=22.19\tGlobalRate=23.18\n",
      "[xla:4](120)\tLoss=0.025\tRate=22.19\tGlobalRate=23.19\n",
      "[xla:2](120)\tLoss=0.027\tRate=22.19\tGlobalRate=23.19\n",
      "[xla:3](120)\tLoss=0.028\tRate=22.19\tGlobalRate=23.18\n",
      "[xla:7](120)\tLoss=0.086\tRate=22.19\tGlobalRate=23.18\n",
      "[xla:5](120)\tLoss=0.067\tRate=22.19\tGlobalRate=23.18\n",
      "[xla:0](120)\tLoss=0.057\tRate=22.19\tGlobalRate=23.19\n",
      "[xla:1](120)\tLoss=0.100\tRate=22.19\tGlobalRate=23.18\n",
      "[xla:3] Accuracy=97.41%\n",
      "[xla:7] Accuracy=96.83%\n",
      "[xla:5] Accuracy=97.36%\n",
      "[xla:0] Accuracy=97.51%\n",
      "[xla:2] Accuracy=97.51%\n",
      "[xla:6] Accuracy=97.22%\n",
      "[xla:4] Accuracy=96.92%\n",
      "[xla:1] Accuracy=97.46%\n",
      "Finished training epoch 21 train-acc 97.51 in 85.79 sec\n",
      "[xla:2](0)\tLoss=0.028\tRate=5.99\tGlobalRate=5.99\n",
      "[xla:6](0)\tLoss=0.184\tRate=6.03\tGlobalRate=6.03\n",
      "[xla:1](0)\tLoss=0.008\tRate=6.00\tGlobalRate=6.00\n",
      "[xla:0](0)\tLoss=0.213\tRate=6.01\tGlobalRate=6.01\n",
      "[xla:7](0)\tLoss=0.071\tRate=5.97\tGlobalRate=5.97\n",
      "[xla:5](0)\tLoss=0.084\tRate=5.97\tGlobalRate=5.97\n",
      "[xla:3](0)\tLoss=0.056\tRate=6.01\tGlobalRate=6.01\n",
      "[xla:4](0)\tLoss=0.050\tRate=6.05\tGlobalRate=6.05\n",
      "[xla:6](40)\tLoss=0.033\tRate=17.20\tGlobalRate=22.92\n",
      "[xla:0](40)\tLoss=0.169\tRate=17.19\tGlobalRate=22.91\n",
      "[xla:7](40)\tLoss=0.019\tRate=17.17\tGlobalRate=22.90\n",
      "[xla:4](40)\tLoss=0.227\tRate=17.21\tGlobalRate=22.93\n",
      "[xla:1](40)\tLoss=0.034\tRate=17.19\tGlobalRate=22.91\n",
      "[xla:3](40)\tLoss=0.093\tRate=17.19\tGlobalRate=22.91\n",
      "[xla:2](40)\tLoss=0.012\tRate=17.18\tGlobalRate=22.90\n",
      "[xla:5](40)\tLoss=0.025\tRate=17.17\tGlobalRate=22.89\n",
      "[xla:6](80)\tLoss=0.013\tRate=21.28\tGlobalRate=23.44\n",
      "[xla:7](80)\tLoss=0.126\tRate=21.27\tGlobalRate=23.43\n",
      "[xla:2](80)\tLoss=0.328\tRate=21.27\tGlobalRate=23.43\n",
      "[xla:5](80)\tLoss=0.225\tRate=21.27\tGlobalRate=23.43\n",
      "[xla:0](80)\tLoss=0.245\tRate=21.28\tGlobalRate=23.44\n",
      "[xla:3](80)\tLoss=0.159\tRate=21.28\tGlobalRate=23.44\n",
      "[xla:1](80)\tLoss=0.027\tRate=21.28\tGlobalRate=23.44\n",
      "[xla:4](80)\tLoss=0.021\tRate=21.28\tGlobalRate=23.44\n",
      "[xla:3](120)\tLoss=0.071\tRate=24.02\tGlobalRate=24.19\n",
      "[xla:7](120)\tLoss=0.055\tRate=24.02\tGlobalRate=24.18\n",
      "[xla:0](120)\tLoss=0.015\tRate=24.03\tGlobalRate=24.19\n",
      "[xla:5](120)\tLoss=0.036\tRate=24.02\tGlobalRate=24.18\n",
      "[xla:6](120)\tLoss=0.009\tRate=24.03\tGlobalRate=24.19\n",
      "[xla:4](120)\tLoss=0.026\tRate=24.03\tGlobalRate=24.19\n",
      "[xla:2](120)\tLoss=0.030\tRate=24.02\tGlobalRate=24.18\n",
      "[xla:1](120)\tLoss=0.033\tRate=24.02\tGlobalRate=24.18\n",
      "[xla:4] Accuracy=97.31%\n",
      "[xla:6] Accuracy=96.92%\n",
      "[xla:2] Accuracy=97.90%\n",
      "[xla:1] Accuracy=97.41%\n",
      "[xla:7] Accuracy=97.41%\n",
      "[xla:3] Accuracy=97.61%\n",
      "[xla:0] Accuracy=97.46%\n",
      "[xla:5] Accuracy=97.46%\n",
      "Finished training epoch 22 train-acc 97.46 in 82.53 sec\n",
      "[xla:7](0)\tLoss=0.110\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:1](0)\tLoss=0.074\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:0](0)\tLoss=0.103\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:2](0)\tLoss=0.008\tRate=5.50\tGlobalRate=5.50\n",
      "[xla:3](0)\tLoss=0.037\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:5](0)\tLoss=0.063\tRate=5.55\tGlobalRate=5.55\n",
      "[xla:4](0)\tLoss=0.043\tRate=5.49\tGlobalRate=5.49\n",
      "[xla:6](0)\tLoss=0.089\tRate=5.52\tGlobalRate=5.52\n",
      "[xla:4](40)\tLoss=0.108\tRate=16.69\tGlobalRate=22.31\n",
      "[xla:0](40)\tLoss=0.139\tRate=16.71\tGlobalRate=22.33\n",
      "[xla:2](40)\tLoss=0.156\tRate=16.70\tGlobalRate=22.31\n",
      "[xla:5](40)\tLoss=0.220\tRate=16.72\tGlobalRate=22.34\n",
      "[xla:1](40)\tLoss=0.124\tRate=16.70\tGlobalRate=22.32\n",
      "[xla:6](40)\tLoss=0.051\tRate=16.71\tGlobalRate=22.33\n",
      "[xla:7](40)\tLoss=0.207\tRate=16.70\tGlobalRate=22.32\n",
      "[xla:3](40)\tLoss=0.452\tRate=16.71\tGlobalRate=22.33\n",
      "[xla:3](80)\tLoss=0.329\tRate=21.33\tGlobalRate=23.31\n",
      "[xla:1](80)\tLoss=0.107\tRate=21.32\tGlobalRate=23.30\n",
      "[xla:6](80)\tLoss=0.023\tRate=21.33\tGlobalRate=23.31\n",
      "[xla:5](80)\tLoss=0.123\tRate=21.33\tGlobalRate=23.31\n",
      "[xla:0](80)\tLoss=0.016\tRate=21.33\tGlobalRate=23.31\n",
      "[xla:7](80)\tLoss=0.025\tRate=21.33\tGlobalRate=23.30\n",
      "[xla:4](80)\tLoss=0.125\tRate=21.32\tGlobalRate=23.30\n",
      "[xla:2](80)\tLoss=0.016\tRate=21.33\tGlobalRate=23.30\n",
      "[xla:5](120)\tLoss=0.023\tRate=23.46\tGlobalRate=23.81\n",
      "[xla:6](120)\tLoss=0.105\tRate=23.46\tGlobalRate=23.80\n",
      "[xla:1](120)\tLoss=0.014\tRate=23.46\tGlobalRate=23.80\n",
      "[xla:7](120)\tLoss=0.171\tRate=23.45\tGlobalRate=23.80\n",
      "[xla:2](120)\tLoss=0.070\tRate=23.45\tGlobalRate=23.80\n",
      "[xla:3](120)\tLoss=0.047\tRate=23.44\tGlobalRate=23.80\n",
      "[xla:4](120)\tLoss=0.045\tRate=23.44\tGlobalRate=23.79\n",
      "[xla:0](120)\tLoss=0.105\tRate=23.44\tGlobalRate=23.80\n",
      "[xla:1] Accuracy=97.56%\n",
      "[xla:3] Accuracy=96.68%\n",
      "[xla:7] Accuracy=97.75%\n",
      "[xla:4] Accuracy=97.31%\n",
      "[xla:0] Accuracy=97.36%\n",
      "[xla:6] Accuracy=97.31%\n",
      "[xla:5] Accuracy=97.61%\n",
      "[xla:2] Accuracy=97.46%\n",
      "Finished training epoch 23 train-acc 97.36 in 83.69 sec\n",
      "[xla:5](0)\tLoss=0.206\tRate=5.78\tGlobalRate=5.78\n",
      "[xla:6](0)\tLoss=0.050\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:1](0)\tLoss=0.370\tRate=5.75\tGlobalRate=5.75\n",
      "[xla:0](0)\tLoss=0.335\tRate=5.76\tGlobalRate=5.76\n",
      "[xla:3](0)\tLoss=0.237\tRate=5.79\tGlobalRate=5.79\n",
      "[xla:2](0)\tLoss=0.091\tRate=5.75\tGlobalRate=5.75\n",
      "[xla:7](0)\tLoss=0.260\tRate=5.74\tGlobalRate=5.74\n",
      "[xla:4](0)\tLoss=0.057\tRate=5.85\tGlobalRate=5.85\n",
      "[xla:6](40)\tLoss=0.016\tRate=17.21\tGlobalRate=22.98\n",
      "[xla:2](40)\tLoss=0.020\tRate=17.19\tGlobalRate=22.96\n",
      "[xla:4](40)\tLoss=0.119\tRate=17.23\tGlobalRate=23.00\n",
      "[xla:0](40)\tLoss=0.115\tRate=17.19\tGlobalRate=22.96\n",
      "[xla:1](40)\tLoss=0.055\tRate=17.19\tGlobalRate=22.96\n",
      "[xla:5](40)\tLoss=0.057\tRate=17.20\tGlobalRate=22.97\n",
      "[xla:3](40)\tLoss=0.107\tRate=17.20\tGlobalRate=22.97\n",
      "[xla:7](40)\tLoss=0.298\tRate=17.18\tGlobalRate=22.95\n",
      "[xla:5](80)\tLoss=0.537\tRate=21.93\tGlobalRate=23.97\n",
      "[xla:6](80)\tLoss=0.079\tRate=21.93\tGlobalRate=23.97\n",
      "[xla:4](80)\tLoss=0.034\tRate=21.94\tGlobalRate=23.98\n",
      "[xla:7](80)\tLoss=0.040\tRate=21.92\tGlobalRate=23.96\n",
      "[xla:1](80)\tLoss=0.123\tRate=21.92\tGlobalRate=23.96\n",
      "[xla:0](80)\tLoss=0.023\tRate=21.93\tGlobalRate=23.96\n",
      "[xla:3](80)\tLoss=0.062\tRate=21.93\tGlobalRate=23.97\n",
      "[xla:2](80)\tLoss=0.067\tRate=21.92\tGlobalRate=23.96\n",
      "[xla:4](120)\tLoss=0.248\tRate=23.46\tGlobalRate=24.14\n",
      "[xla:3](120)\tLoss=0.025\tRate=23.45\tGlobalRate=24.13\n",
      "[xla:1](120)\tLoss=0.028\tRate=23.45\tGlobalRate=24.12\n",
      "[xla:0](120)\tLoss=0.078\tRate=23.45\tGlobalRate=24.13\n",
      "[xla:5](120)\tLoss=0.165\tRate=23.45\tGlobalRate=24.13\n",
      "[xla:6](120)\tLoss=0.051\tRate=23.45\tGlobalRate=24.13\n",
      "[xla:7](120)\tLoss=0.043\tRate=23.45\tGlobalRate=24.12\n",
      "[xla:2](120)\tLoss=0.215\tRate=23.45\tGlobalRate=24.13\n",
      "[xla:5] Accuracy=97.02%\n",
      "[xla:0] Accuracy=97.75%\n",
      "[xla:2] Accuracy=97.31%\n",
      "[xla:7] Accuracy=97.66%\n",
      "Finished training epoch 24 train-acc 97.75 in 82.72 sec\n",
      "[xla:6] Accuracy=97.46%\n",
      "[xla:3] Accuracy=97.22%\n",
      "[xla:4] Accuracy=97.75%\n",
      "[xla:1] Accuracy=97.41%\n",
      "[xla:0](0)\tLoss=0.061\tRate=5.94\tGlobalRate=5.94\n",
      "[xla:7](0)\tLoss=0.073\tRate=5.89\tGlobalRate=5.89\n",
      "[xla:6](0)\tLoss=0.092\tRate=5.95\tGlobalRate=5.95\n",
      "[xla:3](0)\tLoss=0.233\tRate=5.92\tGlobalRate=5.92\n",
      "[xla:1](0)\tLoss=0.142\tRate=5.89\tGlobalRate=5.89\n",
      "[xla:5](0)\tLoss=0.107\tRate=5.88\tGlobalRate=5.88\n",
      "[xla:4](0)\tLoss=0.171\tRate=5.89\tGlobalRate=5.89\n",
      "[xla:2](0)\tLoss=0.100\tRate=5.90\tGlobalRate=5.90\n",
      "[xla:0](40)\tLoss=0.061\tRate=17.26\tGlobalRate=23.03\n",
      "[xla:6](40)\tLoss=0.039\tRate=17.26\tGlobalRate=23.02\n",
      "[xla:2](40)\tLoss=0.020\tRate=17.25\tGlobalRate=23.01\n",
      "[xla:1](40)\tLoss=0.142\tRate=17.24\tGlobalRate=23.00\n",
      "[xla:4](40)\tLoss=0.077\tRate=17.24\tGlobalRate=23.01\n",
      "[xla:3](40)\tLoss=0.052\tRate=17.25\tGlobalRate=23.02\n",
      "[xla:7](40)\tLoss=0.155\tRate=17.24\tGlobalRate=23.00\n",
      "[xla:5](40)\tLoss=0.043\tRate=17.24\tGlobalRate=23.00\n",
      "[xla:1](80)\tLoss=0.040\tRate=21.51\tGlobalRate=23.65\n",
      "[xla:7](80)\tLoss=0.045\tRate=21.51\tGlobalRate=23.65\n",
      "[xla:5](80)\tLoss=0.013\tRate=21.51\tGlobalRate=23.65\n",
      "[xla:6](80)\tLoss=0.007\tRate=21.52\tGlobalRate=23.66\n",
      "[xla:0](80)\tLoss=0.087\tRate=21.52\tGlobalRate=23.66\n",
      "[xla:2](80)\tLoss=0.076\tRate=21.51\tGlobalRate=23.66\n",
      "[xla:4](80)\tLoss=0.028\tRate=21.51\tGlobalRate=23.65\n",
      "[xla:3](80)\tLoss=0.066\tRate=21.51\tGlobalRate=23.66\n",
      "[xla:4](120)\tLoss=0.108\tRate=23.49\tGlobalRate=24.02\n",
      "[xla:0](120)\tLoss=0.030\tRate=23.49\tGlobalRate=24.03\n",
      "[xla:3](120)\tLoss=0.048\tRate=23.49\tGlobalRate=24.02\n",
      "[xla:7](120)\tLoss=0.045\tRate=23.49\tGlobalRate=24.02\n",
      "[xla:2](120)\tLoss=0.045\tRate=23.48\tGlobalRate=24.02\n",
      "[xla:6](120)\tLoss=0.106\tRate=23.49\tGlobalRate=24.03\n",
      "[xla:1](120)\tLoss=0.230\tRate=23.49\tGlobalRate=24.02\n",
      "[xla:5](120)\tLoss=0.015\tRate=23.49\tGlobalRate=24.02\n",
      "[xla:6] Accuracy=97.41%\n",
      "[xla:0] Accuracy=97.27%\n",
      "Finished training epoch 25 train-acc 97.27 in 82.68 sec\n",
      "[xla:2] Accuracy=98.00%\n",
      "[xla:4] Accuracy=97.46%\n",
      "[xla:1] Accuracy=97.17%\n",
      "[xla:3] Accuracy=98.14%\n",
      "[xla:7] Accuracy=97.41%\n",
      "[xla:5] Accuracy=97.56%\n"
     ]
    }
   ],
   "source": [
    "# Start training processes\n",
    "def _mp_fn(rank, flags):\n",
    "    global acc_list\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    a = train_model()\n",
    "\n",
    "FLAGS={}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09005f9ee3f74f0c847b9de4ba561013": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "10e392bc982f4ad0aa696bd2ec951de0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_43c05557786d4781b38b163acca9b407",
        "IPY_MODEL_29dbe36b0516427593169d2d4c038774"
       ],
       "layout": "IPY_MODEL_5d5cd60ec7da43fe8d226c76cdf9e3e3"
      }
     },
     "29dbe36b0516427593169d2d4c038774": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e59325f6e7f6424c9f299c74925730de",
       "placeholder": "​",
       "style": "IPY_MODEL_e89b6408255d49b4be10b8d90a39fe9f",
       "value": " 77.4M/77.4M [00:00&lt;00:00, 165MB/s]"
      }
     },
     "43c05557786d4781b38b163acca9b407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_09005f9ee3f74f0c847b9de4ba561013",
       "max": 81131730.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eca7abe620dc4deba471d61e0c3a34b0",
       "value": 81131730.0
      }
     },
     "5d5cd60ec7da43fe8d226c76cdf9e3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e59325f6e7f6424c9f299c74925730de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e89b6408255d49b4be10b8d90a39fe9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eca7abe620dc4deba471d61e0c3a34b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
